{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Late Airline Arrivals\n",
    "\n",
    "In this project, I will use various machine learning techniques on a dataset of late airline arrivals to predict flight delay. A flight will only count as late if it is over 30 minutes late. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import cross_validation\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn import neighbors\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's take a look at the data we have for the year 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7009728, 29)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1955</td>\n",
       "      <td>2211.0</td>\n",
       "      <td>2225</td>\n",
       "      <td>WN</td>\n",
       "      <td>335</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>754.0</td>\n",
       "      <td>735</td>\n",
       "      <td>1002.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>WN</td>\n",
       "      <td>3231</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>628.0</td>\n",
       "      <td>620</td>\n",
       "      <td>804.0</td>\n",
       "      <td>750</td>\n",
       "      <td>WN</td>\n",
       "      <td>448</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>926.0</td>\n",
       "      <td>930</td>\n",
       "      <td>1054.0</td>\n",
       "      <td>1100</td>\n",
       "      <td>WN</td>\n",
       "      <td>1746</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1829.0</td>\n",
       "      <td>1755</td>\n",
       "      <td>1959.0</td>\n",
       "      <td>1925</td>\n",
       "      <td>WN</td>\n",
       "      <td>3920</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "0  2008      1           3          4   2003.0        1955   2211.0   \n",
       "1  2008      1           3          4    754.0         735   1002.0   \n",
       "2  2008      1           3          4    628.0         620    804.0   \n",
       "3  2008      1           3          4    926.0         930   1054.0   \n",
       "4  2008      1           3          4   1829.0        1755   1959.0   \n",
       "\n",
       "   CRSArrTime UniqueCarrier  FlightNum        ...         TaxiIn  TaxiOut  \\\n",
       "0        2225            WN        335        ...            4.0      8.0   \n",
       "1        1000            WN       3231        ...            5.0     10.0   \n",
       "2         750            WN        448        ...            3.0     17.0   \n",
       "3        1100            WN       1746        ...            3.0      7.0   \n",
       "4        1925            WN       3920        ...            3.0     10.0   \n",
       "\n",
       "   Cancelled  CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n",
       "0          0               NaN         0           NaN          NaN      NaN   \n",
       "1          0               NaN         0           NaN          NaN      NaN   \n",
       "2          0               NaN         0           NaN          NaN      NaN   \n",
       "3          0               NaN         0           NaN          NaN      NaN   \n",
       "4          0               NaN         0           2.0          0.0      0.0   \n",
       "\n",
       "   SecurityDelay  LateAircraftDelay  \n",
       "0            NaN                NaN  \n",
       "1            NaN                NaN  \n",
       "2            NaN                NaN  \n",
       "3            NaN                NaN  \n",
       "4            0.0               32.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2008 = pd.read_csv('2008.csv')\n",
    "print(y2008.shape)\n",
    "y2008.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 29 features and 7,009,728 datapoints. Let's see what kind of features we are working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7009728 entries, 0 to 7009727\n",
      "Data columns (total 29 columns):\n",
      "Year                 int64\n",
      "Month                int64\n",
      "DayofMonth           int64\n",
      "DayOfWeek            int64\n",
      "DepTime              float64\n",
      "CRSDepTime           int64\n",
      "ArrTime              float64\n",
      "CRSArrTime           int64\n",
      "UniqueCarrier        object\n",
      "FlightNum            int64\n",
      "TailNum              object\n",
      "ActualElapsedTime    float64\n",
      "CRSElapsedTime       float64\n",
      "AirTime              float64\n",
      "ArrDelay             float64\n",
      "DepDelay             float64\n",
      "Origin               object\n",
      "Dest                 object\n",
      "Distance             int64\n",
      "TaxiIn               float64\n",
      "TaxiOut              float64\n",
      "Cancelled            int64\n",
      "CancellationCode     object\n",
      "Diverted             int64\n",
      "CarrierDelay         float64\n",
      "WeatherDelay         float64\n",
      "NASDelay             float64\n",
      "SecurityDelay        float64\n",
      "LateAircraftDelay    float64\n",
      "dtypes: float64(14), int64(10), object(5)\n",
      "memory usage: 1.5+ GB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(y2008.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many of these features appear to be directly related to the delay, such as WeatherDelay, NASDelay, Security Delay. Others appear to be arbitrarily assigned, such as FlightNum and UniqueCarrier. Features are a mixture of integers, floats, and objects. Categorical objects may be helpful to us in our analysis but may also be too sparsely distributed to be valuable.\n",
    "\n",
    "Let's look into what kind of values are comprising these features and how those values are correlated with the outcome feature. For each feature that has less than 50 values, we will plot the average delay per value to see if certain values are associated with more delay. This will give us an idea of what features might be important enough to keep as dummy features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature:  Year\n",
      "1 values\n",
      "[2008]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEZCAYAAACQK04eAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqTEGvyQ1xuCXpMb8H/8woF7gFRxGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x179487e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature:  Month\n",
      "12 values\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAENCAYAAAAfTp5aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDHRJasT/AWZkxTZrlFfxAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14ab6af98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature:  DayofMonth\n",
      "31 values\n",
      "[ 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n",
      " 28 29 30 31  2  1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAENCAYAAAAfTp5aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nktSI/w9As3LsSoWSkAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1119fcf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature:  DayOfWeek\n",
      "7 values\n",
      "[4 5 6 7 1 2 3]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEGCAYAAAB1iW6ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAADpxJREFUeJzt3X2MZXV9x/H3hwctQiVQxi0RcDUFdU3LqiNQIA2GhyK2\nQlujpZWgkW6bgGI0bSg1Uv9ogqatpRXaLuWxAWpRCRDa8tSmVlyQARZ50qoUC2TZHSIRFFoFvv3j\nnK3DusOduXdm7syP9yuZzL3nnrn3u5OZ95w9c86ZVBWSpJVvh3EPIElaGAZdkhph0CWpEQZdkhph\n0CWpEQZdkhph0CWpEQZdkhph0CWpETst5YvttddetXr16qV8SUla8e64447Hq2pi0HpLGvTVq1cz\nNTW1lC8pSSteku/MZT13uUhSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDXCoEtSIwy6JDViSU8skqSV\nYPUZ1y3q8z909jsX5XndQpekRhh0SWqEQZekRhh0SWqEQZekRhh0SWqEhy1Ky9BKPWxO4+UWuiQ1\nwqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1Ylkfh+6xuJI0d26hS1IjDLokNcKgS1IjDLokNcKg\nS1IjDLokNcKgS1IjBh6HnmRf4FJgFVDA+qo6J8mewOeA1cBDwHuq6onFG3Xl8Th6SUtpLlvozwIf\nq6o1wCHAqUnWAGcAN1fV/sDN/X1J0pgMDHpVbaqqO/vbTwEPAK8Gjgcu6Ve7BDhhsYaUJA02r1P/\nk6wG3gzcBqyqqk39Q4/R7ZLZ3sesA9YB7LfffsPOKc2Lu7v0UjTnX4om2Q34AvCRqnpy5mNVVXT7\n139CVa2vqsmqmpyYmBhpWEnS7OYU9CQ708X8sqr6Yr94c5K9+8f3BrYszoiSpLkYGPQkAS4AHqiq\nP5/x0DXAyf3tk4GrF348SdJczWUf+mHAScA9STb2y84Ezgb+MckHge8A71mcESVJczEw6FX1ZSCz\nPHzkwo4jSRqWZ4pKUiMMuiQ1Yln/CTpJK5PnAYyHQdesFvOb0m9IaeG5y0WSGmHQJakRBl2SGmHQ\nJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakR\nBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2SGmHQJakRBl2S\nGmHQJakRBl2SGmHQJakRA4Oe5MIkW5LcO2PZHyd5NMnG/u24xR1TkjTIXLbQLwaO3c7yz1TV2v7t\nnxZ2LEnSfA0MelV9CfjuEswiSRrBKPvQP5Tka/0umT1mWynJuiRTSaamp6dHeDlJ0osZNuh/DbwO\nWAtsAv5sthWran1VTVbV5MTExJAvJ0kaZKigV9Xmqnquqp4HzgcOWtixJEnzNVTQk+w94+6vAffO\ntq4kaWnsNGiFJFcARwB7JXkEOAs4IslaoICHgN9dxBklSXMwMOhVdeJ2Fl+wCLNIkkbgmaKS1AiD\nLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmN\nMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS\n1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1AiDLkmNMOiS1IiBQU9yYZItSe6d\nsWzPJDcm+Wb/fo/FHVOSNMhcttAvBo7dZtkZwM1VtT9wc39fkjRGA4NeVV8CvrvN4uOBS/rblwAn\nLPBckqR5GnYf+qqq2tTffgxYNduKSdYlmUoyNT09PeTLSZIGGfmXolVVQL3I4+urarKqJicmJkZ9\nOUnSLIYN+uYkewP077cs3EiSpGEMG/RrgJP72ycDVy/MOJKkYc3lsMUrgA3A65M8kuSDwNnA0Um+\nCRzV35ckjdFOg1aoqhNneejIBZ5FkjQCzxSVpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYY\ndElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElq\nhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGXpEYYdElqhEGX\npEYYdElqhEGXpEYYdElqxE6jfHCSh4CngOeAZ6tqciGGkiTN30hB7729qh5fgOeRJI3AXS6S1IhR\ng17ATUnuSLJueyskWZdkKsnU9PT0iC8nSZrNqEE/vKrWAu8ATk3yS9uuUFXrq2qyqiYnJiZGfDlJ\n0mxGCnpVPdq/3wJcBRy0EENJkuZv6KAn2TXJT2+9DRwD3LtQg0mS5meUo1xWAVcl2fo8l1fVvyzI\nVJKkeRs66FX1IHDgAs4iSRqBhy1KUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBL\nUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMM\nuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1wqBLUiMMuiQ1\nwqBLUiMMuiQ1YqSgJzk2yTeSfCvJGQs1lCRp/oYOepIdgXOBdwBrgBOTrFmowSRJ8zPKFvpBwLeq\n6sGq+iHwD8DxCzOWJGm+UlXDfWDybuDYqjqlv38ScHBVnbbNeuuAdf3d1wPfGH7cgfYCHl/E519s\nzj8+K3l2cP5xW+z5X1NVE4NW2mkRBwCgqtYD6xf7dQCSTFXV5FK81mJw/vFZybOD84/bcpl/lF0u\njwL7zri/T79MkjQGowT9dmD/JK9N8jLgN4FrFmYsSdJ8Db3LpaqeTXIacD2wI3BhVd23YJMNZ0l2\n7Swi5x+flTw7OP+4LYv5h/6lqCRpefFMUUlqhEGXpEYYdElqhEGXpEYY9DFJ8oYkRybZbZvlx45r\npvlIclCSt/W31yT5aJLjxj3XsJJcOu4ZhpXk8P7zf8y4Z5mLJAcneWV/e5ckn0xybZJPJdl93PMN\nkuTDSfYdvObSa/IolyQfqKqLxj3HbJJ8GDgVeABYC5xeVVf3j91ZVW8Z53yDJDmL7qJsOwE3AgcD\n/wYcDVxfVX8yxvEGSrLt+RIB3g78K0BVvWvJh5qHJF+tqoP6279D97V0FXAMcG1VnT3O+QZJch9w\nYH/o83rgaeDzwJH98l8f64ADJPke8APg28AVwJVVNT3eqTqtBv2/q2q/cc8xmyT3AL9YVd9Pspru\ni/nvq+qcJHdV1ZvHOuAA/fxrgZcDjwH7VNWTSXYBbquqXxjrgAMkuRO4H/g7oOiCfgXdyXFU1b+P\nb7rBZn6NJLkdOK6qppPsCtxaVT8/3glfXJIHquqN/e0XbMAk2VhVa8c33WBJ7gLeChwFvBd4F3AH\n3dfQF6vqqXHNtujXclksSb4220PAqqWcZQg7VNX3AarqoSRHAJ9P8hq6+Ze7Z6vqOeDpJN+uqicB\nquqZJM+Peba5mAROB/4I+P2q2pjkmeUe8hl2SLIH3S7THbduHVbVD5I8O97R5uTeGf+LvjvJZFVN\nJTkA+NG4h5uDqqrngRuAG5LsTPc/1hOBPwUGXkRrsazYoNNF+5eBJ7ZZHuArSz/OvGxOsraqNgL0\nW+q/AlwILOutq94Pk7yiqp6m21IBoN//ueyD3n8zfibJlf37zays74Xd6bYIA1SSvatqU//7mJWw\nQXAKcE6Sj9NdoXBDkoeBh/vHlrsXfI6r6kd0lz25JskrxjNSZ8XucklyAXBRVX15O49dXlW/NYax\n5iTJPnRbuY9t57HDquqWMYw1Z0leXlX/u53lewF7V9U9YxhraEneCRxWVWeOe5ZR9DFZVVX/Ne5Z\n5qL/xehr6X6YPlJVm8c80pwkOaCq/nPcc2zPig26JOmFPGxRkhph0CWpEQZdy1KS55JsTHJfkruT\nfCzJKH/U/PAkX03y9f5t3YzHJpLcluSuJGcl+YsZj/1tkptm3P9Qkr8ccoaH+t8zSItiJf1mXy8t\nz2w9HjnJq4DLgVcCZ833iZL8bP/xJ1TVnX1Ur0/yaFVdR3dCyz1VdUqSSeC8GR9+ILBjkh37QzUP\nBa4e6V8mLRK30LXsVdUWuj80flo6q5P8R5I7+7dDoTt9P8kJWz8uyWVJjqc7k/Liqrqzf77HgT8A\nzkiyFvg0cHySjXR/xPyA/pT03YFngI38+HDSQ4Fb+ud/X7/Vv7Hfkt+xX35Mkg39bFfmJy/vsEuS\nf+7P8pQWjEHXilBVD9L9ZaxXAVuAo/szDN8LbN0FcgHwfvj/Y+IPBa4D3kR33PZMU8Cb+nMBPgF8\nrqrW9mf53QW8DTgEuA24FTg0yavpjgx7OMkb+9c+rP+fxHPAb/db/x8HjurnmwI+OuN1dwOuBa6o\nqvMX5JMj9dzlopVoZ+Cz/db1c8AB0J2yn+S8JBPAbwBf6K8XMt/n/wrdD4NdgA3AN4EzgWl+fNLa\nkXQnVd3eP/8udD9oDgHWALf0y1/WP8dWVwOfrqrL5juUNIhB14qQ5HV08d5Ctx99M93+7R2A/5mx\n6qXA++iuy/KBftn9dPGdue/7rcBsfwP3FuD3gJ8CzqUL+RpeGPQAl1TVH24z568CN1bViS/y3Mf2\nJ795EogWlLtctOz1W9x/A3y2j+DuwKb+FP6T6HbFbHUx8BGAqrq/X3Yu8P5+i54kPwN8im7f+fZs\noNvSnqiqLf1rTgPH0+8/B24G3t3/wpYke/bX4rkVOCzJz/XLd+2vUbLVJ+guV3HuMJ8L6cUYdC1X\nu2w9bBG4ie5CSJ/sHzsPODnJ3cAb6C5lCkB/+vgDwEUzlm2i22o/P8nX6bayL6yqa7f3wlX1BF3A\nZ27Bb6Dbf393v879dPvKb+gvFHcj3WUPpun241/RL9/QzzjT6f2/b7YfKNJQPPVfTemvZ3IP8Jaq\n+t6455GWklvoakaSo+i2zv/KmOulyC10SWqEW+iS1AiDLkmNMOiS1AiDLkmNMOiS1Ij/A4WVsivK\nFTyEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11712aa90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature:  DepTime\n",
      "1441 values\n",
      "[ 2003.   754.   628.   926.  1829.  1940.  1937.  1039.   617.  1620.]\n",
      "\n",
      "Feature:  CRSDepTime\n",
      "1217 values\n",
      "[1955  735  620  930 1755 1915 1830 1040  615 1620]\n",
      "\n",
      "Feature:  ArrTime\n",
      "1441 values\n",
      "[ 2211.  1002.   804.  1054.  1959.  2121.  2037.  1132.   652.  1639.]\n",
      "\n",
      "Feature:  CRSArrTime\n",
      "1378 values\n",
      "[2225 1000  750 1100 1925 2110 1940 1150  650 1655]\n",
      "\n",
      "Feature:  UniqueCarrier\n",
      "20 values\n",
      "['WN' 'XE' 'YV' 'OH' 'OO' 'UA' 'US' 'DL' 'EV' 'F9' 'FL' 'HA' 'MQ' 'NW' '9E'\n",
      " 'AA' 'AQ' 'AS' 'B6' 'CO']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAERCAYAAABrWly6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrBIOdDOzSjjQzcwq4UA3M6vE/wcmxi7boqtnQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118ac1a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature:  FlightNum\n",
      "7539 values\n",
      "[ 335 3231  448 1746 3920  378  509  535   11  810]\n",
      "\n",
      "Feature:  TailNum\n",
      "5374 values\n",
      "['N712SW' 'N772SW' 'N428WN' 'N612SW' 'N464WN' 'N726SW' 'N763SW' 'N689SW'\n",
      " 'N648SW' 'N690SW']\n",
      "\n",
      "Feature:  ActualElapsedTime\n",
      "690 values\n",
      "[ 128.   96.   88.   90.  101.  240.  233.   95.   79.  130.]\n",
      "\n",
      "Feature:  CRSElapsedTime\n",
      "526 values\n",
      "[ 150.  145.   90.  115.  250.   95.  135.   55.   50.  240.]\n",
      "\n",
      "Feature:  AirTime\n",
      "664 values\n",
      "[ 116.  113.   76.   78.   77.   87.  230.  219.   70.  106.]\n",
      "\n",
      "Feature:  ArrDelay\n",
      "1154 values\n",
      "[-14.   2.  14.  -6.  34.  11.  57. -18. -16.   1.]\n",
      "\n",
      "Feature:  DepDelay\n",
      "1135 values\n",
      "[  8.  19.  -4.  34.  25.  67.  -1.   2.   0.   6.]\n",
      "\n",
      "Feature:  Origin\n",
      "303 values\n",
      "['IAD' 'IND' 'ISP' 'JAN' 'JAX' 'LAS' 'LAX' 'LBB' 'LIT' 'MAF']\n",
      "\n",
      "Feature:  Dest\n",
      "304 values\n",
      "['TPA' 'BWI' 'JAX' 'LAS' 'MCI' 'MCO' 'MDW' 'PHX' 'FLL' 'PBI']\n",
      "\n",
      "Feature:  Distance\n",
      "1435 values\n",
      "[ 810  515  688 1591  451  828  162 1489  838  220]\n",
      "\n",
      "Feature:  TaxiIn\n",
      "191 values\n",
      "[  4.   5.   3.   7.   6.   9.   2.   8.  40.  10.]\n",
      "\n",
      "Feature:  TaxiOut\n",
      "343 values\n",
      "[  8.  10.  17.   7.  19.   6.  12.  21.   9.  16.]\n",
      "\n",
      "Feature:  Cancelled\n",
      "2 values\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118b56518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature:  CancellationCode\n",
      "5 values\n",
      "[nan 'A' 'C' 'B' 'D']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEICAYAAABbOlNNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118e07e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature:  Diverted\n",
      "2 values\n",
      "[0 1]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118cbf780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature:  CarrierDelay\n",
      "985 values\n",
      "[ nan   2.  10.   8.   3.   0.  12.   7.  40.   5.]\n",
      "\n",
      "Feature:  WeatherDelay\n",
      "600 values\n",
      "[  nan    0.   24.   12.   22.    7.   25.  135.    3.    1.]\n",
      "\n",
      "Feature:  NASDelay\n",
      "575 values\n",
      "[ nan   0.   6.  28.   4.  22.   8.   5.   7.  10.]\n",
      "\n",
      "Feature:  SecurityDelay\n",
      "157 values\n",
      "[ nan   0.  10.   8.  12.   3.   9.   6.  11.  14.]\n",
      "\n",
      "Feature:  LateAircraftDelay\n",
      "565 values\n",
      "[ nan  32.  47.  72.  12.  16.  25.   7.  59.  69.]\n"
     ]
    }
   ],
   "source": [
    "for column in y2008.columns:\n",
    "    print('\\nFeature: ', str(column))\n",
    "    print(len(y2008[column].unique()), 'values')\n",
    "\n",
    "    if len(y2008[column].unique()) < 50:\n",
    "        print(y2008[column].unique())\n",
    "        \n",
    "        mean_per_value = y2008[[column,'LateAircraftDelay']].groupby(column).aggregate(np.mean)\n",
    "        mean_per_value['LateAircraftDelay'].plot(kind = 'bar')\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(y2008[column].unique()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that month may have an effect on aircraft delay. Day of the month is variable but there are no obvious trends; day of the week is somewhat constant.\n",
    "\n",
    "Unique carrier seems to have a dramatic effect on the dekay, with FL demonstrating the most and OH demonstrating the least. For the rest of the categorical features, there is too wide a range of values to create dummy features, as it would add too many features to the dataset. We will create dummy categories for Unique Carrier and drop the rest of the categorical features.\n",
    "\n",
    "We will also drop the numerical feature 'FlightNum' as it is assigned arbitrarily and has no predictive power. 'Cancelled' and 'Diverted' will be dropped because they are outcomes, not contributing features; canceled and diverted flights are incapable of experiencing delay. However, they are also unable to be grouped under \"on-time\", so we will also remove all rows that are positive for either of these features. <br>\n",
    "\n",
    "It may also be wise to remove all forms of delay: although they are numerical, they are too closely linked to the outcome of interest and will likely lead to overfitting. We will keep them for the time being as we continue exploring the data.\n",
    "\n",
    "I will also drop the categorical feature UniqueCarrier because although certain carriers might be more prone to delays, adding 20 dummy features to our already large dataframe is too computationally expensive at this time. I will drop TailNum, Origin, and Dest for the same reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6855029, 29)\n",
      "   Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
      "0  2008      1           3          4   2003.0        1955   2211.0   \n",
      "1  2008      1           3          4    754.0         735   1002.0   \n",
      "2  2008      1           3          4    628.0         620    804.0   \n",
      "3  2008      1           3          4    926.0         930   1054.0   \n",
      "4  2008      1           3          4   1829.0        1755   1959.0   \n",
      "\n",
      "   CRSArrTime  ActualElapsedTime  CRSElapsedTime        ...         \\\n",
      "0        2225              128.0           150.0        ...          \n",
      "1        1000              128.0           145.0        ...          \n",
      "2         750               96.0            90.0        ...          \n",
      "3        1100               88.0            90.0        ...          \n",
      "4        1925               90.0            90.0        ...          \n",
      "\n",
      "   UniqueCarrier_HA  UniqueCarrier_MQ  UniqueCarrier_NW  UniqueCarrier_OH  \\\n",
      "0                 0                 0                 0                 0   \n",
      "1                 0                 0                 0                 0   \n",
      "2                 0                 0                 0                 0   \n",
      "3                 0                 0                 0                 0   \n",
      "4                 0                 0                 0                 0   \n",
      "\n",
      "   UniqueCarrier_OO  UniqueCarrier_UA  UniqueCarrier_US  UniqueCarrier_WN  \\\n",
      "0                 0                 0                 0                 1   \n",
      "1                 0                 0                 0                 1   \n",
      "2                 0                 0                 0                 1   \n",
      "3                 0                 0                 0                 1   \n",
      "4                 0                 0                 0                 1   \n",
      "\n",
      "   UniqueCarrier_XE  UniqueCarrier_YV  \n",
      "0                 0                 0  \n",
      "1                 0                 0  \n",
      "2                 0                 0  \n",
      "3                 0                 0  \n",
      "4                 0                 0  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "(6855029, 41)\n"
     ]
    }
   ],
   "source": [
    "# Dropping all rows with canceled or diverted flights\n",
    "y2008_red = y2008[y2008['Cancelled'] == 0]\n",
    "y2008_red = y2008_red[y2008_red['Diverted'] == 0]\n",
    "print(y2008_red.shape)\n",
    "# Dropping some features and converting others to dummies\n",
    "y2008_red = y2008_red.drop(['FlightNum', 'TailNum', 'Origin','Dest', 'Cancelled', 'CancellationCode', 'Diverted'], axis = 1)\n",
    "y2008_red = pd.get_dummies(y2008_red, columns = ['UniqueCarrier'])\n",
    "print(y2008_red.head())\n",
    "print(y2008_red.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That got rid of a few hundred thousand rows. We eliminated some columns, but added more dummy features so now we have 41 columns. Now, let's take a look at the range of delays for all the flights in our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0       825317\n",
      "15.0       19069\n",
      "16.0       17678\n",
      "17.0       16738\n",
      "18.0       15856\n",
      "19.0       14969\n",
      "20.0       14925\n",
      "21.0       13808\n",
      "22.0       13327\n",
      "14.0       13287\n",
      "13.0       12818\n",
      "23.0       12416\n",
      "12.0       12396\n",
      "24.0       12221\n",
      "10.0       12009\n",
      "11.0       11985\n",
      "25.0       11932\n",
      "9.0        11461\n",
      "7.0        10922\n",
      "8.0        10917\n",
      "26.0       10878\n",
      "6.0        10577\n",
      "27.0       10518\n",
      "28.0       10172\n",
      "29.0        9737\n",
      "30.0        9513\n",
      "31.0        8995\n",
      "5.0         8929\n",
      "4.0         8544\n",
      "32.0        8532\n",
      "           ...  \n",
      "443.0          1\n",
      "442.0          1\n",
      "438.0          1\n",
      "1316.0         1\n",
      "423.0          1\n",
      "418.0          1\n",
      "487.0          1\n",
      "496.0          1\n",
      "572.0          1\n",
      "500.0          1\n",
      "570.0          1\n",
      "568.0          1\n",
      "565.0          1\n",
      "562.0          1\n",
      "552.0          1\n",
      "551.0          1\n",
      "543.0          1\n",
      "540.0          1\n",
      "539.0          1\n",
      "535.0          1\n",
      "530.0          1\n",
      "528.0          1\n",
      "526.0          1\n",
      "524.0          1\n",
      "515.0          1\n",
      "514.0          1\n",
      "512.0          1\n",
      "507.0          1\n",
      "501.0          1\n",
      "661.0          1\n",
      "Name: LateAircraftDelay, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(y2008_red['LateAircraftDelay'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delays range between 15 minutes to 661 minutes (11 hrs). However, we must remember that flights are only considered late if they are over 30 minutes late. Let's take a look at the correlations we can observe between features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Year     Month  DayofMonth  DayOfWeek   DepTime  \\\n",
      "Year                NaN       NaN         NaN        NaN       NaN   \n",
      "Month               NaN  1.000000   -0.000402  -0.005350 -0.010321   \n",
      "DayofMonth          NaN -0.000402    1.000000   0.004762 -0.001555   \n",
      "DayOfWeek           NaN -0.005350    0.004762   1.000000  0.005660   \n",
      "DepTime             NaN -0.010321   -0.001555   0.005660  1.000000   \n",
      "CRSDepTime          NaN -0.008426   -0.001745   0.005666  0.968550   \n",
      "ArrTime             NaN -0.000377   -0.001505   0.003376  0.713081   \n",
      "CRSArrTime          NaN  0.000353   -0.001744   0.005569  0.791431   \n",
      "ActualElapsedTime   NaN -0.014061    0.000598   0.012929 -0.017070   \n",
      "CRSElapsedTime      NaN -0.006345    0.001384   0.015013 -0.013684   \n",
      "AirTime             NaN -0.012413    0.000950   0.013915 -0.023170   \n",
      "ArrDelay            NaN -0.042058    0.001607   0.010558  0.178275   \n",
      "DepDelay            NaN -0.030498    0.003299   0.015425  0.201981   \n",
      "Distance            NaN -0.005558    0.001363   0.016730 -0.016523   \n",
      "TaxiIn              NaN  0.006904   -0.002933   0.010244 -0.042255   \n",
      "TaxiOut             NaN -0.016249   -0.000674  -0.007207  0.050649   \n",
      "CarrierDelay        NaN -0.000232    0.000249   0.012319  0.001787   \n",
      "WeatherDelay        NaN  0.005598    0.001249   0.006441  0.023042   \n",
      "NASDelay            NaN  0.013533    0.004114  -0.007274 -0.013341   \n",
      "SecurityDelay       NaN -0.003165   -0.000276   0.004513 -0.009065   \n",
      "LateAircraftDelay   NaN  0.002176    0.009385   0.012024  0.205079   \n",
      "UniqueCarrier_9E    NaN  0.007009    0.000366  -0.000266  0.004050   \n",
      "UniqueCarrier_AA    NaN  0.005291    0.001613   0.005093 -0.005104   \n",
      "UniqueCarrier_AQ    NaN -0.048553   -0.000717   0.000295 -0.002586   \n",
      "UniqueCarrier_AS    NaN  0.000869   -0.000828   0.001737 -0.000076   \n",
      "UniqueCarrier_B6    NaN  0.000742    0.002010   0.005896  0.006956   \n",
      "UniqueCarrier_CO    NaN -0.004232    0.000305  -0.002021 -0.010209   \n",
      "UniqueCarrier_DL    NaN  0.008458   -0.001272  -0.001080 -0.007969   \n",
      "UniqueCarrier_EV    NaN  0.006363   -0.001101   0.000281 -0.007956   \n",
      "UniqueCarrier_F9    NaN  0.002654    0.000033   0.001054  0.001227   \n",
      "UniqueCarrier_FL    NaN  0.002763    0.000788   0.007126  0.011484   \n",
      "UniqueCarrier_HA    NaN  0.011363    0.000496   0.004503 -0.005203   \n",
      "UniqueCarrier_MQ    NaN -0.003429    0.000361  -0.000102 -0.014138   \n",
      "UniqueCarrier_NW    NaN -0.010852   -0.001174   0.000487 -0.002036   \n",
      "UniqueCarrier_OH    NaN -0.011487   -0.000085  -0.005291  0.000946   \n",
      "UniqueCarrier_OO    NaN -0.000729   -0.000299   0.000660 -0.001894   \n",
      "UniqueCarrier_UA    NaN -0.003868    0.000187   0.003342 -0.003136   \n",
      "UniqueCarrier_US    NaN  0.002557   -0.000902  -0.002930  0.007898   \n",
      "UniqueCarrier_WN    NaN  0.011945   -0.000178  -0.006842  0.018826   \n",
      "UniqueCarrier_XE    NaN -0.024868   -0.000045  -0.006131 -0.011564   \n",
      "UniqueCarrier_YV    NaN  0.004806    0.000397   0.003144  0.010916   \n",
      "\n",
      "                   CRSDepTime   ArrTime  CRSArrTime  ActualElapsedTime  \\\n",
      "Year                      NaN       NaN         NaN                NaN   \n",
      "Month               -0.008426 -0.000377    0.000353          -0.014061   \n",
      "DayofMonth          -0.001745 -0.001505   -0.001744           0.000598   \n",
      "DayOfWeek            0.005666  0.003376    0.005569           0.012929   \n",
      "DepTime              0.968550  0.713081    0.791431          -0.017070   \n",
      "CRSDepTime           1.000000  0.697293    0.790820          -0.017184   \n",
      "ArrTime              0.697293  1.000000    0.862455           0.037625   \n",
      "CRSArrTime           0.790820  0.862455    1.000000           0.051469   \n",
      "ActualElapsedTime   -0.017184  0.037625    0.051469           1.000000   \n",
      "CRSElapsedTime      -0.011774  0.038654    0.056583           0.979875   \n",
      "AirTime             -0.021086  0.030320    0.044016           0.984241   \n",
      "ArrDelay             0.116894  0.066021    0.113087           0.093925   \n",
      "DepDelay             0.138850  0.073540    0.132823           0.044380   \n",
      "Distance            -0.012189  0.029023    0.046196           0.964521   \n",
      "TaxiIn              -0.047563  0.007132   -0.006540           0.158444   \n",
      "TaxiOut              0.039827  0.049583    0.059792           0.267801   \n",
      "CarrierDelay        -0.053916 -0.058128   -0.053370          -0.032919   \n",
      "WeatherDelay         0.006909 -0.020296    0.007568          -0.013712   \n",
      "NASDelay            -0.052253  0.019385   -0.010596           0.203805   \n",
      "SecurityDelay       -0.011447 -0.005345   -0.009237           0.000318   \n",
      "LateAircraftDelay    0.191594 -0.009715    0.153406          -0.087003   \n",
      "UniqueCarrier_9E     0.004935  0.003920    0.001032          -0.082810   \n",
      "UniqueCarrier_AA    -0.007934  0.016939    0.023262           0.172304   \n",
      "UniqueCarrier_AQ    -0.001501 -0.005495   -0.006079          -0.025642   \n",
      "UniqueCarrier_AS     0.002488 -0.000212   -0.001104           0.054777   \n",
      "UniqueCarrier_B6     0.013204 -0.012716   -0.002645           0.123293   \n",
      "UniqueCarrier_CO    -0.011894  0.006514    0.015008           0.171757   \n",
      "UniqueCarrier_DL    -0.006492  0.007663    0.007866           0.108165   \n",
      "UniqueCarrier_EV    -0.010792 -0.009368   -0.015469          -0.097311   \n",
      "UniqueCarrier_F9     0.004055  0.008580    0.014947           0.027619   \n",
      "UniqueCarrier_FL     0.014485  0.006802    0.008571          -0.001379   \n",
      "UniqueCarrier_HA    -0.003112 -0.010649   -0.010818          -0.050098   \n",
      "UniqueCarrier_MQ    -0.017847 -0.019755   -0.027997          -0.143951   \n",
      "UniqueCarrier_NW     0.000152  0.008880    0.009614           0.042661   \n",
      "UniqueCarrier_OH    -0.001502  0.003471    0.000952          -0.043786   \n",
      "UniqueCarrier_OO    -0.001850 -0.012072   -0.018150          -0.152405   \n",
      "UniqueCarrier_UA    -0.005839 -0.006516   -0.005447           0.157215   \n",
      "UniqueCarrier_US     0.016160  0.005715    0.005801           0.065468   \n",
      "UniqueCarrier_WN     0.015559  0.006951    0.007000          -0.131237   \n",
      "UniqueCarrier_XE    -0.014601 -0.004174   -0.005128          -0.044952   \n",
      "UniqueCarrier_YV     0.010958 -0.008413   -0.010924          -0.105502   \n",
      "\n",
      "                   CRSElapsedTime        ...         UniqueCarrier_HA  \\\n",
      "Year                          NaN        ...                      NaN   \n",
      "Month                   -0.006345        ...                 0.011363   \n",
      "DayofMonth               0.001384        ...                 0.000496   \n",
      "DayOfWeek                0.015013        ...                 0.004503   \n",
      "DepTime                 -0.013684        ...                -0.005203   \n",
      "CRSDepTime              -0.011774        ...                -0.003112   \n",
      "ArrTime                  0.038654        ...                -0.010649   \n",
      "CRSArrTime               0.056583        ...                -0.010818   \n",
      "ActualElapsedTime        0.979875        ...                -0.050098   \n",
      "CRSElapsedTime           1.000000        ...                -0.054092   \n",
      "AirTime                  0.988173        ...                -0.040656   \n",
      "ArrDelay                 0.012641        ...                -0.017021   \n",
      "DepDelay                 0.035356        ...                -0.025574   \n",
      "Distance                 0.983176        ...                -0.027886   \n",
      "TaxiIn                   0.104174        ...                -0.025931   \n",
      "TaxiOut                  0.143128        ...                -0.057159   \n",
      "CarrierDelay             0.002979        ...                 0.026173   \n",
      "WeatherDelay            -0.022753        ...                -0.006747   \n",
      "NASDelay                 0.056993        ...                -0.032325   \n",
      "SecurityDelay            0.002910        ...                -0.001276   \n",
      "LateAircraftDelay       -0.038502        ...                -0.009351   \n",
      "UniqueCarrier_9E        -0.081141        ...                -0.018632   \n",
      "UniqueCarrier_AA         0.168942        ...                -0.029007   \n",
      "UniqueCarrier_AQ        -0.026054        ...                -0.003194   \n",
      "UniqueCarrier_AS         0.055630        ...                -0.014124   \n",
      "UniqueCarrier_B6         0.123803        ...                -0.016118   \n",
      "UniqueCarrier_CO         0.174595        ...                -0.020088   \n",
      "UniqueCarrier_DL         0.102996        ...                -0.024978   \n",
      "UniqueCarrier_EV        -0.098346        ...                -0.019400   \n",
      "UniqueCarrier_F9         0.024529        ...                -0.011276   \n",
      "UniqueCarrier_FL        -0.005997        ...                -0.018798   \n",
      "UniqueCarrier_HA        -0.054092        ...                 1.000000   \n",
      "UniqueCarrier_MQ        -0.149280        ...                -0.025787   \n",
      "UniqueCarrier_NW         0.034183        ...                -0.021822   \n",
      "UniqueCarrier_OH        -0.049217        ...                -0.016057   \n",
      "UniqueCarrier_OO        -0.157880        ...                -0.028129   \n",
      "UniqueCarrier_UA         0.162518        ...                -0.024798   \n",
      "UniqueCarrier_US         0.070197        ...                -0.025042   \n",
      "UniqueCarrier_WN        -0.110176        ...                -0.043436   \n",
      "UniqueCarrier_XE        -0.048989        ...                -0.022459   \n",
      "UniqueCarrier_YV        -0.110865        ...                -0.018279   \n",
      "\n",
      "                   UniqueCarrier_MQ  UniqueCarrier_NW  UniqueCarrier_OH  \\\n",
      "Year                            NaN               NaN               NaN   \n",
      "Month                     -0.003429         -0.010852         -0.011487   \n",
      "DayofMonth                 0.000361         -0.001174         -0.000085   \n",
      "DayOfWeek                 -0.000102          0.000487         -0.005291   \n",
      "DepTime                   -0.014138         -0.002036          0.000946   \n",
      "CRSDepTime                -0.017847          0.000152         -0.001502   \n",
      "ArrTime                   -0.019755          0.008880          0.003471   \n",
      "CRSArrTime                -0.027997          0.009614          0.000952   \n",
      "ActualElapsedTime         -0.143951          0.042661         -0.043786   \n",
      "CRSElapsedTime            -0.149280          0.034183         -0.049217   \n",
      "AirTime                   -0.148534          0.030182         -0.059957   \n",
      "ArrDelay                   0.012152         -0.004776          0.016032   \n",
      "DepDelay                   0.005441         -0.022762          0.007622   \n",
      "Distance                  -0.152882          0.031413         -0.072426   \n",
      "TaxiIn                     0.002677          0.066869          0.012605   \n",
      "TaxiOut                   -0.008804          0.055613          0.080287   \n",
      "CarrierDelay              -0.005453          0.019421          0.022167   \n",
      "WeatherDelay               0.009182          0.011413          0.094619   \n",
      "NASDelay                  -0.000206         -0.002283          0.021379   \n",
      "SecurityDelay             -0.009986         -0.002072         -0.005198   \n",
      "LateAircraftDelay          0.015455         -0.056844         -0.084940   \n",
      "UniqueCarrier_9E          -0.053326         -0.045126         -0.033204   \n",
      "UniqueCarrier_AA          -0.083020         -0.070253         -0.051693   \n",
      "UniqueCarrier_AQ          -0.009141         -0.007735         -0.005692   \n",
      "UniqueCarrier_AS          -0.040425         -0.034208         -0.025171   \n",
      "UniqueCarrier_B6          -0.046131         -0.039037         -0.028724   \n",
      "UniqueCarrier_CO          -0.057493         -0.048652         -0.035799   \n",
      "UniqueCarrier_DL          -0.071488         -0.060495         -0.044513   \n",
      "UniqueCarrier_EV          -0.055525         -0.046986         -0.034573   \n",
      "UniqueCarrier_F9          -0.032271         -0.027309         -0.020094   \n",
      "UniqueCarrier_FL          -0.053802         -0.045529         -0.033500   \n",
      "UniqueCarrier_HA          -0.025787         -0.021822         -0.016057   \n",
      "UniqueCarrier_MQ           1.000000         -0.062455         -0.045955   \n",
      "UniqueCarrier_NW          -0.062455          1.000000         -0.038888   \n",
      "UniqueCarrier_OH          -0.045955         -0.038888          1.000000   \n",
      "UniqueCarrier_OO          -0.080508         -0.068128         -0.050129   \n",
      "UniqueCarrier_UA          -0.070974         -0.060060         -0.044193   \n",
      "UniqueCarrier_US          -0.071674         -0.060652         -0.044628   \n",
      "UniqueCarrier_WN          -0.124318         -0.105200         -0.077407   \n",
      "UniqueCarrier_XE          -0.064279         -0.054394         -0.040024   \n",
      "UniqueCarrier_YV          -0.052317         -0.044272         -0.032576   \n",
      "\n",
      "                   UniqueCarrier_OO  UniqueCarrier_UA  UniqueCarrier_US  \\\n",
      "Year                            NaN               NaN               NaN   \n",
      "Month                     -0.000729         -0.003868          0.002557   \n",
      "DayofMonth                -0.000299          0.000187         -0.000902   \n",
      "DayOfWeek                  0.000660          0.003342         -0.002930   \n",
      "DepTime                   -0.001894         -0.003136          0.007898   \n",
      "CRSDepTime                -0.001850         -0.005839          0.016160   \n",
      "ArrTime                   -0.012072         -0.006516          0.005715   \n",
      "CRSArrTime                -0.018150         -0.005447          0.005801   \n",
      "ActualElapsedTime         -0.152405          0.157215          0.065468   \n",
      "CRSElapsedTime            -0.157880          0.162518          0.070197   \n",
      "AirTime                   -0.151492          0.158873          0.062027   \n",
      "ArrDelay                  -0.012081          0.021190         -0.036456   \n",
      "DepDelay                  -0.021193          0.030727         -0.031750   \n",
      "Distance                  -0.156560          0.164544          0.060846   \n",
      "TaxiIn                    -0.044355         -0.003834         -0.022905   \n",
      "TaxiOut                   -0.023130          0.029979          0.046406   \n",
      "CarrierDelay               0.001180         -0.006818         -0.014329   \n",
      "WeatherDelay              -0.001796         -0.017577         -0.022268   \n",
      "NASDelay                   0.001897          0.004251          0.013093   \n",
      "SecurityDelay              0.006189         -0.009475          0.007367   \n",
      "LateAircraftDelay          0.011188          0.051806         -0.025485   \n",
      "UniqueCarrier_9E          -0.058169         -0.051281         -0.051786   \n",
      "UniqueCarrier_AA          -0.090560         -0.079836         -0.080622   \n",
      "UniqueCarrier_AQ          -0.009971         -0.008790         -0.008877   \n",
      "UniqueCarrier_AS          -0.044096         -0.038874         -0.039257   \n",
      "UniqueCarrier_B6          -0.050321         -0.044362         -0.044798   \n",
      "UniqueCarrier_CO          -0.062715         -0.055288         -0.055833   \n",
      "UniqueCarrier_DL          -0.077981         -0.068747         -0.069424   \n",
      "UniqueCarrier_EV          -0.060568         -0.053395         -0.053921   \n",
      "UniqueCarrier_F9          -0.035203         -0.031034         -0.031339   \n",
      "UniqueCarrier_FL          -0.058689         -0.051739         -0.052249   \n",
      "UniqueCarrier_HA          -0.028129         -0.024798         -0.025042   \n",
      "UniqueCarrier_MQ          -0.080508         -0.070974         -0.071674   \n",
      "UniqueCarrier_NW          -0.068128         -0.060060         -0.060652   \n",
      "UniqueCarrier_OH          -0.050129         -0.044193         -0.044628   \n",
      "UniqueCarrier_OO           1.000000         -0.077421         -0.078183   \n",
      "UniqueCarrier_UA          -0.077421          1.000000         -0.068925   \n",
      "UniqueCarrier_US          -0.078183         -0.068925          1.000000   \n",
      "UniqueCarrier_WN          -0.135609         -0.119550         -0.120727   \n",
      "UniqueCarrier_XE          -0.070117         -0.061814         -0.062422   \n",
      "UniqueCarrier_YV          -0.057069         -0.050311         -0.050806   \n",
      "\n",
      "                   UniqueCarrier_WN  UniqueCarrier_XE  UniqueCarrier_YV  \n",
      "Year                            NaN               NaN               NaN  \n",
      "Month                      0.011945         -0.024868          0.004806  \n",
      "DayofMonth                -0.000178         -0.000045          0.000397  \n",
      "DayOfWeek                 -0.006842         -0.006131          0.003144  \n",
      "DepTime                    0.018826         -0.011564          0.010916  \n",
      "CRSDepTime                 0.015559         -0.014601          0.010958  \n",
      "ArrTime                    0.006951         -0.004174         -0.008413  \n",
      "CRSArrTime                 0.007000         -0.005128         -0.010924  \n",
      "ActualElapsedTime         -0.131237         -0.044952         -0.105502  \n",
      "CRSElapsedTime            -0.110176         -0.048989         -0.110865  \n",
      "AirTime                   -0.082907         -0.050970         -0.112537  \n",
      "ArrDelay                  -0.035522          0.015160          0.018040  \n",
      "DepDelay                   0.005190          0.009443          0.011099  \n",
      "Distance                  -0.075319         -0.058177         -0.114325  \n",
      "TaxiIn                    -0.190714          0.011786          0.000846  \n",
      "TaxiOut                   -0.236898          0.019822          0.015948  \n",
      "CarrierDelay              -0.056116         -0.011796          0.084261  \n",
      "WeatherDelay              -0.015050         -0.002827          0.001289  \n",
      "NASDelay                  -0.120227          0.049976         -0.015022  \n",
      "SecurityDelay              0.009494          0.010081          0.008662  \n",
      "LateAircraftDelay          0.097343          0.009832         -0.034829  \n",
      "UniqueCarrier_9E          -0.089823         -0.046443         -0.037801  \n",
      "UniqueCarrier_AA          -0.139839         -0.072304         -0.058849  \n",
      "UniqueCarrier_AQ          -0.015397         -0.007961         -0.006480  \n",
      "UniqueCarrier_AS          -0.068091         -0.035207         -0.028655  \n",
      "UniqueCarrier_B6          -0.077703         -0.040176         -0.032700  \n",
      "UniqueCarrier_CO          -0.096842         -0.050073         -0.040755  \n",
      "UniqueCarrier_DL          -0.120416         -0.062261         -0.050675  \n",
      "UniqueCarrier_EV          -0.093526         -0.048358         -0.039359  \n",
      "UniqueCarrier_F9          -0.054358         -0.028106         -0.022876  \n",
      "UniqueCarrier_FL          -0.090625         -0.046858         -0.038138  \n",
      "UniqueCarrier_HA          -0.043436         -0.022459         -0.018279  \n",
      "UniqueCarrier_MQ          -0.124318         -0.064279         -0.052317  \n",
      "UniqueCarrier_NW          -0.105200         -0.054394         -0.044272  \n",
      "UniqueCarrier_OH          -0.077407         -0.040024         -0.032576  \n",
      "UniqueCarrier_OO          -0.135609         -0.070117         -0.057069  \n",
      "UniqueCarrier_UA          -0.119550         -0.061814         -0.050311  \n",
      "UniqueCarrier_US          -0.120727         -0.062422         -0.050806  \n",
      "UniqueCarrier_WN           1.000000         -0.108271         -0.088123  \n",
      "UniqueCarrier_XE          -0.108271          1.000000         -0.045564  \n",
      "UniqueCarrier_YV          -0.088123         -0.045564          1.000000  \n",
      "\n",
      "[41 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "corrmat = y2008_red.corr()\n",
    "print(corrmat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although there are too many features to get a thorough read, I can tell that CRSDepTime, DepTime, ArrDelay, DepDelay, TaxiOut, CarrierDelay, and NASDelay all have strong correlation with the outcome (magnitude over 0.1). Naturally, arrival delay and departure delay will correlate strongly (above 0.5). In the same way that 'time in minutes' would correlate strongly with 'time in hours', the different categories of delay are correlated with the final delay but they don't add any predictive power. To build a good predictive model, we will remove all associated 'Delay' features because in the real world, we would not have the luxury of knowing these features well enough in advance to make a useful prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y2008_red = y2008_red.drop(['CarrierDelay', 'WeatherDelay', 'NASDelay', 'SecurityDelay','ArrDelay','DepDelay'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at how much null data there is in our dataset so we can account for it when training our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                       0\n",
      "Month                      0\n",
      "DayofMonth                 0\n",
      "DayOfWeek                  0\n",
      "DepTime                    0\n",
      "CRSDepTime                 0\n",
      "ArrTime                    0\n",
      "CRSArrTime                 0\n",
      "ActualElapsedTime          0\n",
      "CRSElapsedTime             0\n",
      "AirTime                    0\n",
      "Distance                   0\n",
      "TaxiIn                     0\n",
      "TaxiOut                    0\n",
      "LateAircraftDelay    5330294\n",
      "UniqueCarrier_9E           0\n",
      "UniqueCarrier_AA           0\n",
      "UniqueCarrier_AQ           0\n",
      "UniqueCarrier_AS           0\n",
      "UniqueCarrier_B6           0\n",
      "UniqueCarrier_CO           0\n",
      "UniqueCarrier_DL           0\n",
      "UniqueCarrier_EV           0\n",
      "UniqueCarrier_F9           0\n",
      "UniqueCarrier_FL           0\n",
      "UniqueCarrier_HA           0\n",
      "UniqueCarrier_MQ           0\n",
      "UniqueCarrier_NW           0\n",
      "UniqueCarrier_OH           0\n",
      "UniqueCarrier_OO           0\n",
      "UniqueCarrier_UA           0\n",
      "UniqueCarrier_US           0\n",
      "UniqueCarrier_WN           0\n",
      "UniqueCarrier_XE           0\n",
      "UniqueCarrier_YV           0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Calculate NaN values for each column\n",
    "print(y2008_red.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After dropping some columns, we see that the outcome is the only feature with NaN values. These value correspond to all the flights that experienced no delay. We will want to convert these to 0, as they will provide a valuable control group for the delayed flights. If we want to model delayed flights, it will be helpful to have a basis of non-delayed flights to compare them to. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year                 0\n",
      "Month                0\n",
      "DayofMonth           0\n",
      "DayOfWeek            0\n",
      "DepTime              0\n",
      "CRSDepTime           0\n",
      "ArrTime              0\n",
      "CRSArrTime           0\n",
      "ActualElapsedTime    0\n",
      "CRSElapsedTime       0\n",
      "AirTime              0\n",
      "Distance             0\n",
      "TaxiIn               0\n",
      "TaxiOut              0\n",
      "LateAircraftDelay    0\n",
      "UniqueCarrier_9E     0\n",
      "UniqueCarrier_AA     0\n",
      "UniqueCarrier_AQ     0\n",
      "UniqueCarrier_AS     0\n",
      "UniqueCarrier_B6     0\n",
      "UniqueCarrier_CO     0\n",
      "UniqueCarrier_DL     0\n",
      "UniqueCarrier_EV     0\n",
      "UniqueCarrier_F9     0\n",
      "UniqueCarrier_FL     0\n",
      "UniqueCarrier_HA     0\n",
      "UniqueCarrier_MQ     0\n",
      "UniqueCarrier_NW     0\n",
      "UniqueCarrier_OH     0\n",
      "UniqueCarrier_OO     0\n",
      "UniqueCarrier_UA     0\n",
      "UniqueCarrier_US     0\n",
      "UniqueCarrier_WN     0\n",
      "UniqueCarrier_XE     0\n",
      "UniqueCarrier_YV     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert NaN values in outcome to 0\n",
    "y2008_red[column] = y2008_red[column].replace(to_replace = 'NaN', value = 0)\n",
    "print(y2008_red.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's separate the late flights from the on-time flights so we can evenly sample them and prevent class imbalance. Although we are trying to predict how late flights will be, we will need just as many on-time flights to serve as a comparison for when the predicted flight delay is 0-30 min (considered on-time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Delayed Flights: 337060\n",
      "Number of On-time Flights: 1187675\n"
     ]
    }
   ],
   "source": [
    "late = y2008_red.ix[y2008['LateAircraftDelay'] > 30]\n",
    "print('Number of Delayed Flights:', len(late))\n",
    "\n",
    "on_time = y2008_red.ix[y2008['LateAircraftDelay'] <= 30]\n",
    "print('Number of On-time Flights:', len(on_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are many more on-time flights than delayed flights, we will need to choose a random sample of on-time flights to match the size of the delayed sample. We will the combine them back into one dataset for input into our machine learning models. <br>\n",
    "\n",
    "I will also reserve 20% of the data for external validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "on_time_red = on_time.sample(len(late))\n",
    "combined = late.append(on_time_red, ignore_index=True)\n",
    "X = combined.drop('LateAircraftDelay',axis=1)\n",
    "Y = combined['LateAircraftDelay']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will try a K Nearest Neighbors regressor. I will use 5 fold cross-validation on the training dataset to prevent overfitting. I will select the parameters that give the best cross-validation score for use on the external validation set. Since I am using regression, I will judge different models based on their resultant R2 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year\n",
      "[2008]\n",
      "Month\n",
      "[ 1  2  3  4  5  6  7  8  9 10 11 12]\n",
      "DayofMonth\n",
      "[ 3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27\n",
      " 28 29 30 31  2  1]\n",
      "DayOfWeek\n",
      "[4 5 6 7 1 2 3]\n",
      "DepTime\n",
      "[ 1829.  1937.  1644. ...,   518.   451.   437.]\n",
      "CRSDepTime\n",
      "[1755 1830 1510 ...,  558  513  146]\n",
      "ArrTime\n",
      "[ 1959.  2037.  1845. ...,   446.   437.   513.]\n",
      "CRSArrTime\n",
      "[1925 1940 1725 ...,  437  132  350]\n",
      "ActualElapsedTime\n",
      "[   90.   240.   121.   147.   135.    96.   127.    54.    74.   256.\n",
      "   124.   146.   196.    66.    64.    59.   212.   110.   194.   295.\n",
      "   156.   143.   187.    86.    94.    92.   137.    50.    52.   129.\n",
      "    62.    57.    58.    70.    73.    83.    72.    85.   178.   158.\n",
      "   169.    56.    78.    77.    75.    65.    91.    67.    69.    98.\n",
      "    99.    68.   132.    89.   180.    51.    49.    48.   128.   148.\n",
      "   176.   152.   141.   136.   144.   116.    71.    63.    55.   161.\n",
      "   101.    84.   145.   287.   300.    79.    80.   104.   238.   224.\n",
      "   154.   267.   134.   139.   226.   164.   204.    61.   115.    81.\n",
      "    88.   235.   234.   100.    82.   114.   106.   142.   173.    76.\n",
      "   118.   103.    87.   177.    95.   130.   133.   108.   150.   102.\n",
      "    60.   105.   113.   200.    93.   181.   207.   206.    44.    46.\n",
      "   245.   153.   111.   109.   230.   232.   107.   227.   231.   157.\n",
      "   160.   117.   221.   182.    42.    38.   131.    43.    53.   122.\n",
      "   210.   279.   284.   123.   209.   271.   305.   149.   112.   188.\n",
      "   215.   192.   273.   268.   168.   223.   155.   119.   125.   166.\n",
      "   274.    97.   243.   222.   159.   120.   170.   297.   336.   175.\n",
      "   189.   191.   163.    45.   262.   263.   185.   216.   162.   193.\n",
      "   199.   184.   285.   174.   201.   203.   241.   167.   254.   217.\n",
      "   183.   179.   218.   172.   126.   259.   316.    47.   211.    41.\n",
      "   357.   140.   205.   270.   251.   198.   190.   258.   282.   278.\n",
      "   208.   138.   202.   225.   244.   171.   266.   253.   265.   186.\n",
      "    39.   343.   312.   323.   277.   257.   219.   248.   220.   165.\n",
      "   246.   233.   195.    36.   314.   213.   272.   320.   228.   151.\n",
      "   249.   242.   229.   289.   276.   247.   348.   299.   250.   197.\n",
      "   252.   214.   351.   298.    40.   260.   239.   302.    37.   269.\n",
      "   349.   264.   291.   292.    35.   313.   237.   281.   283.   255.\n",
      "   288.   304.   290.   303.   345.   275.   335.   294.   318.   310.\n",
      "   354.   301.   286.   280.    32.    34.    33.   317.    29.    27.\n",
      "    28.    30.   236.    26.    31.   337.    25.   376.   420.   405.\n",
      "   397.   362.   378.   332.   435.   363.   331.   425.   403.   384.\n",
      "   387.   352.   394.   308.   389.   371.   390.   400.   416.   385.\n",
      "   379.   402.   329.   341.   322.   309.   338.   447.   465.   452.\n",
      "   325.   319.   306.   321.   330.   327.   339.   315.   296.   350.\n",
      "   334.   307.   367.   346.   328.   326.   372.   388.   386.   377.\n",
      "   431.   393.   324.   293.   353.   261.   333.   383.   398.   421.\n",
      "   472.   440.   364.   311.   340.   342.   365.   380.   355.   427.\n",
      "   368.   344.   370.   409.   356.   369.   391.   373.   360.   381.\n",
      "   411.   374.   366.   392.   347.   358.   361.   382.   375.   433.\n",
      "   407.   514.   359.   598.   404.   430.   428.   437.   399.   438.\n",
      "   475.   450.   443.   406.    22.    19.   395.   413.   414.   401.\n",
      "   418.   423.   396.   635.   412.   621.   667.   499.   609.   520.\n",
      "   429.   611.   592.   408.    17.   473.   419.   445.   517.   457.\n",
      "   436.   446.   617.   549.   459.   422.   534.   455.    21.    18.\n",
      "   426.   417.   415.   410.   489.   662.   646.   515.   525.    24.\n",
      "   491.   477.   464.   432.   463.   476.   471.   439.   487.   467.\n",
      "    20.   444.   466.   441.   483.   493.   453.   660.   682.   686.\n",
      "   693.   659.   498.   522.   553.   596.   469.   518.   434.   451.\n",
      "   442.   614.   448.   519.   488.   458.   449.   460.   500.   531.\n",
      "   509.    23.   484.   538.   539.   605.   478.   486.   482.    15.\n",
      "   468.   658.   545.   481.   492.   681.   490.   530.   480.   510.\n",
      "   540.   558.   536.   527.   521.   474.   565.   470.   618.    16.\n",
      "   564.   666.   654.   454.   563.   639.   587.   529.   569.   502.\n",
      "   511.   424.   485.   456.   568.   495.   600.   776.   573.   550.\n",
      "   532.   508.   462.   559.   633.   512.   507.   526.   496.   544.\n",
      "   501.   572.   560.   567.   494.   610.   503.   461.   604.   683.\n",
      "   750.   552.   541.   505.   543.   652.   533.   584.   642.   650.\n",
      "   661.   479.   590.   546.   576.   580.   645.   663.   516.   582.\n",
      "   653.   637.   578.   523.   644.   630.   599.   583.   524.   588.\n",
      "   585.   626.   577.   589.   497.   555.   601.   537.   623.   594.\n",
      "   506.   528.   542.   591.   513.   562.   608.   651.   670.   648.\n",
      "   556.   535.   606.   581.   649.  1114.   612.   586.   554.   551.\n",
      "   571.   631.   593.   595.   504.   597.   656.   711.   579.   575.\n",
      "   616.   657.   548.   638.   561.   624.   620.   674.   602.]\n",
      "CRSElapsedTime\n",
      "[  90.  250.  135.  165.  145.  100.   50.   80.  275.  120.  155.  205.\n",
      "   60.   70.  230.  110.  115.  215.  285.  200.   95.   55.  140.   65.\n",
      "   75.   85.  190.  150.  180.  105.  130.  175.  185.  170.  280.  225.\n",
      "  125.  270.  195.  220.  245.  235.  160.  260.  240.   45.  210.  290.\n",
      "  315.  330.  255.  350.  265.  345.  325.  320.  335.  355.  310.  300.\n",
      "  305.   84.  108.  182.  103.  126.  214.  122.  149.   63.  141.   79.\n",
      "   73.  153.   69.  197.   62.  117.  137.  159.  243.  194.   86.  129.\n",
      "  193.  201.   77.  184.  134.   81.  127.  104.  158.  112.  162.  139.\n",
      "  131.  181.  167.  101.  192.  173.   67.   71.   58.   56.  163.  148.\n",
      "  111.   92.  161.  154.  174.  188.  142.  123.  107.  106.  102.  156.\n",
      "  113.  118.   88.   78.   82.  168.  132.  144.  157.  152.   74.  109.\n",
      "   83.  169.   87.   72.   94.  119.  227.  128.  207.  183.   99.  143.\n",
      "   98.  202.  179.   64.  172.   59.  138.   68.  177.   54.  196.   97.\n",
      "  114.  164.   93.   43.  198.  178.   57.   89.  124.  199.  147.  219.\n",
      "   53.  187.  218.  133.  189.  204.   47.  209.  136.  176.  211.  203.\n",
      "   52.   51.   91.  116.   76.   61.  121.  191.   46.   66.   42.   48.\n",
      "   96.   49.   40.   32.   44.   39.   34.  171.  151.  166.  217.  262.\n",
      "   37.  208.   36.   26.  146.  246.  216.  257.   31.   38.   41.  244.\n",
      "  186.  213.   33.   35.  226.   20.  324.  407.  404.  321.  389.  394.\n",
      "  323.  409.  312.  372.  383.  381.  406.  393.  307.  248.  282.  277.\n",
      "  348.  465.  343.  347.  342.  314.  298.  296.  317.  336.  316.  283.\n",
      "  301.  299.  344.  274.  370.  331.  295.  333.  302.  351.  363.  313.\n",
      "  332.  334.  388.  390.  379.  382.  303.  223.  239.  268.  267.  231.\n",
      "  271.  234.  273.  266.  279.  251.  254.  281.  241.  242.  288.  276.\n",
      "  322.  318.  396.  329.  356.  391.  308.  309.  371.  304.  286.  361.\n",
      "  365.  293.  297.  360.  359.  339.  362.  366.  292.  338.  352.  367.\n",
      "  269.  224.  272.  221.  252.  386.  228.  253.  206.  261.  222.  236.\n",
      "  237.  229.  258.  289.  287.  377.  327.  340.  357.  337.  232.  249.\n",
      "  263.  264.  238.  259.  341.  278.  405.  374.  233.  375.  378.  319.\n",
      "  384.  294.  311.  212.  256.  247.  284.  364.  380.  328.  400.  401.\n",
      "  413.  395.  373.  291.  306.  524.  353.  597.  416.  392.  354.   29.\n",
      "  435.  440.  385.  455.   30.   27.   28.  346.  387.  399.  368.  369.\n",
      "  376.  660.  358.  505.  450.  418.  419.  398.   19.  471.  326.  412.\n",
      "  425.  415.  430.  460.  403.  397.  402.  410.  515.  -21.   24.  474.\n",
      "  476.  441.  456.  420.  408.  458.  510.  600.  601.  512.  525.  443.\n",
      "  349.  584.  490.  495.  445.    1.   15.  526.  585.  463.  635.  422.\n",
      "  452.  573.  529.  533.  417.  472.  528.  436.  432.  577.  485.   25.\n",
      "  575.  437.  532.  438.  468.  442.  522.  414.  580.  500.  552.  411.\n",
      "  446.  604.  477.  560.  421.  565.  423.  427.  556. -140.  480.  587.\n",
      "  540.  549.  478.  479.  481.  511.  531.  547.  444.  473.  548.  595.\n",
      "   12.  541.  513.  579.  520.  514.  523.  536.  439.  535.]\n",
      "AirTime\n",
      "[  7.70000000e+01   2.30000000e+02   1.07000000e+02   1.34000000e+02\n",
      "   1.18000000e+02   8.10000000e+01   1.13000000e+02   3.60000000e+01\n",
      "   6.00000000e+01   2.43000000e+02   9.10000000e+01   1.27000000e+02\n",
      "   1.77000000e+02   4.60000000e+01   4.80000000e+01   4.30000000e+01\n",
      "   1.95000000e+02   8.80000000e+01   1.76000000e+02   2.69000000e+02\n",
      "   1.31000000e+02   1.30000000e+02   1.68000000e+02   7.20000000e+01\n",
      "   7.60000000e+01   7.80000000e+01   1.25000000e+02   3.20000000e+01\n",
      "   1.12000000e+02   4.00000000e+01   5.60000000e+01   4.40000000e+01\n",
      "   4.70000000e+01   4.50000000e+01   6.80000000e+01   5.80000000e+01\n",
      "   5.50000000e+01   6.20000000e+01   6.70000000e+01   1.51000000e+02\n",
      "   1.26000000e+02   5.30000000e+01   8.50000000e+01   1.57000000e+02\n",
      "   4.20000000e+01   6.60000000e+01   6.50000000e+01   6.40000000e+01\n",
      "   7.10000000e+01   5.20000000e+01   7.00000000e+01   5.40000000e+01\n",
      "   4.90000000e+01   8.40000000e+01   8.20000000e+01   6.10000000e+01\n",
      "   5.00000000e+01   1.21000000e+02   1.62000000e+02   3.70000000e+01\n",
      "   4.10000000e+01   1.35000000e+02   1.56000000e+02   1.49000000e+02\n",
      "   1.38000000e+02   1.28000000e+02   1.22000000e+02   9.00000000e+01\n",
      "   7.30000000e+01   1.42000000e+02   1.14000000e+02   2.72000000e+02\n",
      "   2.15000000e+02   2.12000000e+02   1.04000000e+02   2.53000000e+02\n",
      "   2.10000000e+02   1.55000000e+02   5.70000000e+01   1.15000000e+02\n",
      "   1.93000000e+02   5.10000000e+01   9.30000000e+01   6.30000000e+01\n",
      "   2.13000000e+02   2.04000000e+02   8.60000000e+01   3.10000000e+01\n",
      "   8.30000000e+01   1.32000000e+02   1.61000000e+02   9.80000000e+01\n",
      "   1.05000000e+02   3.50000000e+01   1.02000000e+02   1.16000000e+02\n",
      "   1.63000000e+02   7.40000000e+01   1.17000000e+02   1.08000000e+02\n",
      "   9.90000000e+01   1.20000000e+02   1.39000000e+02   9.70000000e+01\n",
      "   1.03000000e+02   1.01000000e+02   7.90000000e+01   1.91000000e+02\n",
      "   1.89000000e+02   8.00000000e+01   7.50000000e+01   2.90000000e+01\n",
      "   3.40000000e+01   2.36000000e+02   6.90000000e+01   5.90000000e+01\n",
      "   2.06000000e+02   2.07000000e+02   9.60000000e+01   3.90000000e+01\n",
      "   1.83000000e+02   2.18000000e+02   1.45000000e+02   1.48000000e+02\n",
      "   1.23000000e+02   2.08000000e+02   1.24000000e+02   1.67000000e+02\n",
      "   1.00000000e+02   9.20000000e+01   2.80000000e+01   9.50000000e+01\n",
      "   1.10000000e+02   9.40000000e+01   1.06000000e+02   1.09000000e+02\n",
      "   1.69000000e+02   3.80000000e+01   2.50000000e+02   2.66000000e+02\n",
      "   1.81000000e+02   2.32000000e+02   8.70000000e+01   2.77000000e+02\n",
      "   1.40000000e+02   1.78000000e+02   1.88000000e+02   2.40000000e+02\n",
      "   2.74000000e+02   1.85000000e+02   1.59000000e+02   1.94000000e+02\n",
      "   1.82000000e+02   1.65000000e+02   2.91000000e+02   2.54000000e+02\n",
      "   2.16000000e+02   1.58000000e+02   8.90000000e+01   1.41000000e+02\n",
      "   1.36000000e+02   1.72000000e+02   1.33000000e+02   1.96000000e+02\n",
      "   2.63000000e+02   2.03000000e+02   3.00000000e+01   1.50000000e+02\n",
      "   1.46000000e+02   3.10000000e+02   1.75000000e+02   1.54000000e+02\n",
      "   1.43000000e+02   2.48000000e+02   1.73000000e+02   1.87000000e+02\n",
      "   1.71000000e+02   1.64000000e+02   1.19000000e+02   2.23000000e+02\n",
      "   2.24000000e+02   2.39000000e+02   2.19000000e+02   1.70000000e+02\n",
      "   2.05000000e+02   2.21000000e+02   1.47000000e+02   1.29000000e+02\n",
      "   2.01000000e+02   1.11000000e+02   1.98000000e+02   3.43000000e+02\n",
      "   2.41000000e+02   1.86000000e+02   1.44000000e+02   2.37000000e+02\n",
      "   2.56000000e+02   1.79000000e+02   2.59000000e+02   1.84000000e+02\n",
      "   2.33000000e+02   2.00000000e+02   2.11000000e+02   2.35000000e+02\n",
      "   2.42000000e+02   2.09000000e+02   1.60000000e+02   3.31000000e+02\n",
      "   2.61000000e+02   3.08000000e+02   3.30000000e+01   2.02000000e+02\n",
      "   2.34000000e+02   2.28000000e+02   2.20000000e+02   2.31000000e+02\n",
      "   2.47000000e+02   2.70000000e+01   1.97000000e+02   2.14000000e+02\n",
      "   2.44000000e+02   2.55000000e+02   3.04000000e+02   2.90000000e+02\n",
      "   1.99000000e+02   2.49000000e+02   1.37000000e+02   2.27000000e+02\n",
      "   1.92000000e+02   2.29000000e+02   1.80000000e+02   1.52000000e+02\n",
      "   2.87000000e+02   2.82000000e+02   1.53000000e+02   1.90000000e+02\n",
      "   2.22000000e+02   2.84000000e+02   1.74000000e+02   2.46000000e+02\n",
      "   2.25000000e+02   2.79000000e+02   2.45000000e+02   2.26000000e+02\n",
      "   3.24000000e+02   2.17000000e+02   2.76000000e+02   3.01000000e+02\n",
      "   2.95000000e+02   2.50000000e+01   2.97000000e+02   2.57000000e+02\n",
      "   2.60000000e+02   2.96000000e+02   2.38000000e+02   2.58000000e+02\n",
      "   1.66000000e+02   2.62000000e+02   2.71000000e+02   2.70000000e+02\n",
      "   3.00000000e+00   2.60000000e+01   1.60000000e+01   2.40000000e+01\n",
      "   2.30000000e+01   1.80000000e+01   1.90000000e+01   2.10000000e+01\n",
      "   2.20000000e+01   1.70000000e+01   2.00000000e+01   1.50000000e+01\n",
      "   1.40000000e+01   2.00000000e+00   1.00000000e+00   0.00000000e+00\n",
      "   1.30000000e+01   3.11000000e+02   3.09000000e+02   3.45000000e+02\n",
      "   3.44000000e+02   3.77000000e+02   3.71000000e+02   3.40000000e+02\n",
      "   3.52000000e+02   3.05000000e+02   3.87000000e+02   3.35000000e+02\n",
      "   3.65000000e+02   3.62000000e+02   3.51000000e+02   3.41000000e+02\n",
      "   3.29000000e+02   3.63000000e+02   2.86000000e+02   3.39000000e+02\n",
      "   3.23000000e+02   3.21000000e+02   2.80000000e+02   3.28000000e+02\n",
      "   3.67000000e+02   3.48000000e+02   3.14000000e+02   3.58000000e+02\n",
      "   2.52000000e+02   3.12000000e+02   2.78000000e+02   2.85000000e+02\n",
      "   3.16000000e+02   2.93000000e+02   4.15000000e+02   4.49000000e+02\n",
      "   4.28000000e+02   3.06000000e+02   3.22000000e+02   3.15000000e+02\n",
      "   3.00000000e+02   3.19000000e+02   2.92000000e+02   3.13000000e+02\n",
      "   2.75000000e+02   3.27000000e+02   3.20000000e+02   3.32000000e+02\n",
      "   2.94000000e+02   2.64000000e+02   3.02000000e+02   3.30000000e+02\n",
      "   3.74000000e+02   2.67000000e+02   2.65000000e+02   2.81000000e+02\n",
      "   2.51000000e+02   2.98000000e+02   3.03000000e+02   2.99000000e+02\n",
      "   3.66000000e+02   3.73000000e+02   4.02000000e+02   4.09000000e+02\n",
      "   3.98000000e+02   3.33000000e+02   3.53000000e+02   3.07000000e+02\n",
      "   3.25000000e+02   3.37000000e+02   3.61000000e+02   3.59000000e+02\n",
      "   2.68000000e+02   3.17000000e+02   3.26000000e+02   3.36000000e+02\n",
      "   3.54000000e+02   3.57000000e+02   3.47000000e+02   3.18000000e+02\n",
      "   3.49000000e+02   3.38000000e+02   2.73000000e+02   3.89000000e+02\n",
      "   2.89000000e+02   3.42000000e+02   3.34000000e+02   2.83000000e+02\n",
      "   3.68000000e+02   4.86000000e+02   5.69000000e+02   3.70000000e+02\n",
      "   4.10000000e+02   4.12000000e+02   3.50000000e+02   4.16000000e+02\n",
      "   4.14000000e+02   4.04000000e+02   3.72000000e+02   3.80000000e+02\n",
      "   4.22000000e+02   4.51000000e+02   4.32000000e+02   2.88000000e+02\n",
      "   3.55000000e+02   3.60000000e+02   3.64000000e+02   3.84000000e+02\n",
      "   8.00000000e+00   3.46000000e+02   1.00000000e+01   1.20000000e+01\n",
      "   3.93000000e+02   1.10000000e+01   3.69000000e+02   3.79000000e+02\n",
      "   3.75000000e+02   3.56000000e+02   6.07000000e+02   5.94000000e+02\n",
      "   6.28000000e+02   4.77000000e+02   3.88000000e+02   5.70000000e+02\n",
      "   4.13000000e+02   4.96000000e+02   5.92000000e+02   5.72000000e+02\n",
      "   7.00000000e+00   4.56000000e+02   4.23000000e+02   3.78000000e+02\n",
      "   3.95000000e+02   5.84000000e+02   4.90000000e+02   4.37000000e+02\n",
      "   4.08000000e+02   3.82000000e+02   4.06000000e+02   9.00000000e+00\n",
      "   3.85000000e+02   4.74000000e+02   6.39000000e+02   6.20000000e+02\n",
      "   4.94000000e+02   5.01000000e+02   5.00000000e+00   4.64000000e+02\n",
      "   4.55000000e+02   4.39000000e+02   4.29000000e+02   3.96000000e+02\n",
      "   4.01000000e+02   4.48000000e+02   3.81000000e+02   3.76000000e+02\n",
      "   6.00000000e+00   4.38000000e+02   4.19000000e+02   4.53000000e+02\n",
      "   4.36000000e+02   4.11000000e+02   3.99000000e+02   4.35000000e+02\n",
      "   4.03000000e+02   3.92000000e+02   3.83000000e+02   4.76000000e+02\n",
      "   6.34000000e+02   6.22000000e+02   6.45000000e+02   6.41000000e+02\n",
      "   6.32000000e+02   4.83000000e+02   4.91000000e+02   5.39000000e+02\n",
      "   5.73000000e+02   5.11000000e+02   3.86000000e+02   3.94000000e+02\n",
      "   5.79000000e+02   4.24000000e+02   4.63000000e+02   4.65000000e+02\n",
      "   4.00000000e+02   4.30000000e+02   4.20000000e+02   4.44000000e+02\n",
      "   4.79000000e+02   4.97000000e+02   4.73000000e+02   4.68000000e+02\n",
      "   5.17000000e+02   5.71000000e+02   5.77000000e+02   4.50000000e+02\n",
      "   4.05000000e+02   4.25000000e+02   6.10000000e+02   4.61000000e+02\n",
      "   4.60000000e+02   4.46000000e+02   4.75000000e+02   5.27000000e+02\n",
      "   3.91000000e+02   4.21000000e+02   5.36000000e+02   5.08000000e+02\n",
      "   5.03000000e+02   5.02000000e+02   4.18000000e+02   4.31000000e+02\n",
      "   6.18000000e+02   4.33000000e+02   4.72000000e+02   6.05000000e+02\n",
      "   5.58000000e+02   4.99000000e+02   4.87000000e+02   4.45000000e+02\n",
      "   5.37000000e+02   4.42000000e+02   5.98000000e+02   5.89000000e+02\n",
      "   4.81000000e+02   5.10000000e+02   3.90000000e+02   4.70000000e+02\n",
      "   5.23000000e+02   5.51000000e+02   5.38000000e+02   4.89000000e+02\n",
      "   5.05000000e+02   5.35000000e+02   5.45000000e+02   5.34000000e+02\n",
      "   5.74000000e+02   4.43000000e+02   4.57000000e+02   5.87000000e+02\n",
      "   5.97000000e+02   5.95000000e+02   3.97000000e+02   5.20000000e+02\n",
      "   5.13000000e+02   4.17000000e+02   6.12000000e+02   4.26000000e+02\n",
      "   5.62000000e+02   6.16000000e+02   6.14000000e+02   5.65000000e+02\n",
      "   4.41000000e+02   4.07000000e+02   4.47000000e+02   5.41000000e+02\n",
      "   6.37000000e+02   5.54000000e+02   6.13000000e+02   6.35000000e+02\n",
      "   5.32000000e+02   5.31000000e+02   6.21000000e+02   4.95000000e+02\n",
      "   4.71000000e+02   6.09000000e+02   4.82000000e+02   5.49000000e+02\n",
      "   4.54000000e+02   5.50000000e+02   4.67000000e+02   5.04000000e+02\n",
      "   4.66000000e+02   6.44000000e+02   5.06000000e+02   5.59000000e+02\n",
      "   5.64000000e+02   4.00000000e+00   5.28000000e+02   5.14000000e+02\n",
      "   4.34000000e+02   5.63000000e+02   5.57000000e+02   5.00000000e+02\n",
      "   5.67000000e+02   4.85000000e+02   5.30000000e+02   4.92000000e+02\n",
      "   6.42000000e+02   5.53000000e+02   5.26000000e+02   6.26000000e+02\n",
      "   5.21000000e+02   6.23000000e+02   4.27000000e+02   5.68000000e+02\n",
      "   5.15000000e+02   5.07000000e+02   4.40000000e+02   5.42000000e+02\n",
      "   5.86000000e+02   5.09000000e+02   6.15000000e+02   4.98000000e+02\n",
      "   1.09100000e+03   6.24000000e+02   5.61000000e+02   4.78000000e+02\n",
      "   5.43000000e+02   4.93000000e+02   4.88000000e+02   5.16000000e+02\n",
      "   4.62000000e+02   4.69000000e+02   5.24000000e+02   5.75000000e+02\n",
      "   5.56000000e+02   4.59000000e+02   5.33000000e+02   4.52000000e+02\n",
      "   5.81000000e+02   6.55000000e+02   6.03000000e+02   5.83000000e+02\n",
      "   5.44000000e+02   4.80000000e+02   5.48000000e+02   6.38000000e+02\n",
      "   5.66000000e+02   6.08000000e+02   5.46000000e+02   4.58000000e+02\n",
      "   6.06000000e+02   5.52000000e+02   5.47000000e+02   5.60000000e+02\n",
      "   6.47000000e+02   5.12000000e+02]\n",
      "Distance\n",
      "[ 515 1591  828 ...,  882  117   87]\n",
      "TaxiIn\n",
      "[   3.    6.    8.    4.    5.    2.    9.    7.   20.   19.    1.   17.\n",
      "   15.   11.   10.   33.   14.   13.   21.   22.   16.   35.   18.   25.\n",
      "   27.   12.   23.   24.   29.   39.   31.   48.   28.   26.   30.   52.\n",
      "   32.   41.   34.   54.   91.   40.   66.   65.   44.   59.   43.   49.\n",
      "   85.  123.   46.   45.   36.  132.   58.   70.  114.   42.   93.   47.\n",
      "  105.   71.   64.   88.   96.   60.   50.   38.   37.   51.   55.  115.\n",
      "  121.  125.  101.  145.   76.   97.   89.   53.   61.   79.   75.   90.\n",
      "   73.   77.   57.   69.   67.   63.   83.   68.  100.   81.   84.  151.\n",
      "   94.  120.   82.   72.   56.   62.    0.   92.   74.  163.  160.  107.\n",
      "  131.  147.   80.  141.  113.  200.   99.   87.  207.  106.  199.   95.\n",
      "  103.  117.  112.   98.  110.   86.  149.  133.  136.   78.  178.  116.\n",
      "  118.  111.  119.  134.  104.  122.  126.  138.  159.  171.  173.  109.\n",
      "  129.  143.  184.  137.  135.  102.  128.  240.  130.  140.  179.  176.\n",
      "  124.  153.  168.  233.  144.  127.  154.  139.  308.]\n",
      "TaxiOut\n",
      "[  10.    7.    8.   11.   14.   28.   17.   13.   18.   15.    9.   22.\n",
      "   24.   21.   12.   29.    5.   16.    6.   20.    4.   19.   50.   27.\n",
      "   33.   25.    3.   26.   37.   23.   42.   32.   30.   31.   40.   45.\n",
      "   47.   41.   36.   61.   48.   43.   35.   64.   34.   59.   39.   66.\n",
      "   65.   52.   53.   55.   38.   78.   57.   63.   44.   76.   60.   54.\n",
      "   58.   56.   46.   67.   49.   51.   80.   68.   74.  150.   86.  105.\n",
      "   72.   69.   92.   97.   62.   85.  110.  127.  101.   90.   71.   73.\n",
      "   81.  115.   77.  103.  107.  106.   95.   83.    1.  116.   70.   75.\n",
      "   98.   82.   94.    2.  130.   88.   79.   87.  117.  128.  104.  175.\n",
      "   93.  133.   91.  189.  173.  138.  146.  134.  164.  135.   96.   99.\n",
      "  100.  126.   84.  125.  123.  137.  131.  124.  112.  262.  287.  166.\n",
      "  309.  191.  102.  108.  109.  194.  206.  204.  129.  111.   89.  118.\n",
      "  141.  145.  113.  161.  143.  120.  167.  185.  202.  148.  114.  224.\n",
      "  121.  220.  151.  183.  144.    0.  119.  210.  169.  142.  199.  122.\n",
      "  132.  153.  181.  178.  160.  170.  243.  195.  221.  147.  155.  149.\n",
      "  188.  168.  154.  180.  190.  140.  187.  177.  263.  219.  159.  152.\n",
      "  172.  231.  184.  237.  157.  136.  196.  266.  171.  213.  156.  200.\n",
      "  158.  165.  162.  139.  193.  208.  174.  218.  301.  282.  229.  203.\n",
      "  303.  212.  176.  198.  179.  230.  236.  216.  182.  257.  225.  163.\n",
      "  280.  422.  235.  291.  209.  186.  306.  241.  192.  252.  284.  228.\n",
      "  304.  246.  214.  207.  239.  270.  234.  327.  393.  285.  353.  215.\n",
      "  205.  197.  324.  265.  242.  362.  302.  279.  319.  201.  321.  217.\n",
      "  258.  269.  259.  211.  256.  338.  298.  331.  277.  273.  342.  312.\n",
      "  248.  274.  233.  288.  244.  264.  222.  320.  232.  227.  374.  253.\n",
      "  292.  245.  278.  238.  226.  276.  272.  223.  271.  429.  305.  247.]\n",
      "UniqueCarrier_9E\n",
      "[0 1]\n",
      "UniqueCarrier_AA\n",
      "[0 1]\n",
      "UniqueCarrier_AQ\n",
      "[0 1]\n",
      "UniqueCarrier_AS\n",
      "[0 1]\n",
      "UniqueCarrier_B6\n",
      "[0 1]\n",
      "UniqueCarrier_CO\n",
      "[0 1]\n",
      "UniqueCarrier_DL\n",
      "[0 1]\n",
      "UniqueCarrier_EV\n",
      "[0 1]\n",
      "UniqueCarrier_F9\n",
      "[0 1]\n",
      "UniqueCarrier_FL\n",
      "[0 1]\n",
      "UniqueCarrier_HA\n",
      "[0 1]\n",
      "UniqueCarrier_MQ\n",
      "[0 1]\n",
      "UniqueCarrier_NW\n",
      "[0 1]\n",
      "UniqueCarrier_OH\n",
      "[0 1]\n",
      "UniqueCarrier_OO\n",
      "[0 1]\n",
      "UniqueCarrier_UA\n",
      "[0 1]\n",
      "UniqueCarrier_US\n",
      "[0 1]\n",
      "UniqueCarrier_WN\n",
      "[1 0]\n",
      "UniqueCarrier_XE\n",
      "[0 1]\n",
      "UniqueCarrier_YV\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "for column in X.columns:\n",
    "    print(str(column))\n",
    "    print(X[column].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors = 1\n",
      "Cross Validation Score: 0.27003802218089\n",
      "R2 Score: 1.0\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-8e1e12881e9f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnums\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     \u001b[0mrun_neighbors_cv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mruns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cross-val score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-8e1e12881e9f>\u001b[0m in \u001b[0;36mrun_neighbors_cv\u001b[0;34m(X, Y, num)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcross_validation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[1;32m   1579\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1580\u001b[0m                                               fit_params)\n\u001b[0;32m-> 1581\u001b[0;31m                       for train, test in cv)\n\u001b[0m\u001b[1;32m   1582\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, error_score)\u001b[0m\n\u001b[1;32m   1692\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1693\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1694\u001b[0;31m         \u001b[0mtest_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1695\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1696\u001b[0m             \u001b[0mtrain_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py\u001b[0m in \u001b[0;36m_score\u001b[0;34m(estimator, X_test, y_test, scorer)\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1750\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1751\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1752\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'item'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1753\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/metrics/scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m     \u001b[0;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m         return r2_score(y, self.predict(X), sample_weight=sample_weight,\n\u001b[0m\u001b[1;32m    388\u001b[0m                         multioutput='variance_weighted')\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/neighbors/regression.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m         \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mneigh_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/neighbors/base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    383\u001b[0m                 delayed(self._tree.query, check_pickle=False)(\n\u001b[1;32m    384\u001b[0m                     X[s], n_neighbors, return_distance)\n\u001b[0;32m--> 385\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m             )\n\u001b[1;32m    387\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def run_neighbors_cv(X, Y, num):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors = num)\n",
    "    knn.fit(X, Y)\n",
    "    \n",
    "    scores = cross_validation.cross_val_score(knn, X, Y, cv=5)\n",
    "    Y_pred = knn.predict(X)\n",
    "    \n",
    "    print(f'n_neighbors = {num}')\n",
    "    print(f'Cross Validation Score: {scores.mean()}')\n",
    "    print(f'R2 Score: {r2_score(Y_pred, Y)}')\n",
    "    print('\\n')\n",
    "    \n",
    "    current_run = {'k neighbors': num, 'cross-val score': scores.mean(), 'r2 score': r2_score(Y_pred, Y)}\n",
    "    runs.append(current_run)\n",
    " \n",
    "runs = [] \n",
    "nums = {1,5,15,50}\n",
    "for num in nums:\n",
    "    run_neighbors_cv(X_train, Y_train, num)\n",
    "    \n",
    "runs.sort(key = lambda run: run['cross-val score'])\n",
    "print(runs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using K-nearest neighbors with k values of 1, 5, 15, 50, and 100, we were able to obtain a validation R2 score of 0.582. This was using 50 neighbors. <br>\n",
    "\n",
    "Let's use that value to train the validation dataset and see how this model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k_num = runs[-1]['k neighbors']\n",
    "\n",
    "def run_neighbors_val(X_train, Y_train, X_test, Y_test, k_num):\n",
    "    knn = neighbors.KNeighborsRegressor(n_neighbors = k_num)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    Y_pred = knn.predict(X_test)\n",
    "\n",
    "    print(f'K Neighbors: {k_num}')\n",
    "    print(f'R2 Score: {r2_score(Y_pred, Y_test)}\\n') \n",
    "    \n",
    "run_neighbors_val(X_train, Y_train, X_test, Y_test, k_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best performing parameter gave us a validation score of 0.231, which is far lower than the training score. This means that the model is drastically overfitting the data, which makes sense since it is using such a high number of neighbors. <br>\n",
    "\n",
    "Nonetheless, let's continue with linear regression, which is very computationally cheap and convenient to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_linear_cv(X, Y):\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(X, Y)\n",
    "\n",
    "    scores = cross_validation.cross_val_score(lr, X, Y, cv=5)\n",
    "    Y_pred = lr.predict(X)\n",
    "\n",
    "    print(f'Cross Validation Score: {scores.mean()}')\n",
    "    print(f'R2 Score: {r2_score(Y_pred, Y)}\\n')\n",
    "    \n",
    "    current_run = {'cross-val score': scores.mean(), 'r2 score': r2_score(Y_pred, Y)}\n",
    "    runs.append(current_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.11768185924989291\n",
      "R2 Score: -6.485221812119872\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_linear_cv(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using linear regression on the cross-validated dataset, we can see that linear regression is not a valid way to fit our data. The training r2 value is negative, which means that our model fits the data worse than a horizontal line would. A second machine learning regressor performing poorly indicates that there is something wrong with our dataset and we should take measures to fix the dataset before applying any more machine learning models. <br>\n",
    "\n",
    "Now that we have added quite a few dummy features, our dataset has become very sparse. Let's try using PCA to condense our feature set into fewer, more impactful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of total variance in dataset explained by each component:\n",
      " [  1.28890562e-01   8.14339586e-02   4.20581523e-02   3.55884658e-02\n",
      "   3.53763588e-02   3.31228226e-02   3.30438515e-02   3.25976207e-02\n",
      "   3.22035989e-02   3.21025823e-02   3.19728159e-02   3.19428834e-02\n",
      "   3.17770104e-02   3.15649240e-02   3.13754437e-02   3.11961639e-02\n",
      "   3.10562789e-02   3.07912316e-02   3.06823547e-02   3.04161419e-02\n",
      "   3.01772181e-02   2.93169565e-02   2.75639491e-02   2.69034255e-02\n",
      "   2.51613959e-02   2.36744809e-02   2.21512087e-02   9.15415795e-03\n",
      "   5.37438535e-03   9.13091399e-04   4.16507855e-04   7.53544583e-32\n",
      "   1.60986203e-32   9.95872382e-34]\n",
      "Covariance Matrix:\n",
      " [[ 0.          0.          0.         ...,  0.          0.          0.        ]\n",
      " [ 0.          1.00000185  0.06685753 ...,  0.00647554 -0.02828406\n",
      "   0.00147713]\n",
      " [ 0.          0.06685753  1.00000185 ...,  0.00326358 -0.00209331\n",
      "  -0.00113825]\n",
      " ..., \n",
      " [ 0.          0.00647554  0.00326358 ...,  1.00000185 -0.11253695\n",
      "  -0.08316239]\n",
      " [ 0.         -0.02828406 -0.00209331 ..., -0.11253695  1.00000185\n",
      "  -0.0464117 ]\n",
      " [ 0.          0.00147713 -0.00113825 ..., -0.08316239 -0.0464117\n",
      "   1.00000185]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0vIrOVP0jgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118d48630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvYhIglPQi4gkOAW9iEiCU9CLiCS4/wcQCfYknwSiBwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10c1c9ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_scaled = StandardScaler().fit_transform(X_train)\n",
    "sklearn_pca = PCA()\n",
    "sklearn_pca.fit(X_scaled)\n",
    "\n",
    "print(\n",
    "    'Percentage of total variance in dataset explained by each component:\\n',\n",
    "    sklearn_pca.explained_variance_ratio_\n",
    ")\n",
    "\n",
    "Xt = X_scaled.T\n",
    "Cx = np.cov(Xt)\n",
    "print('Covariance Matrix:\\n', Cx)\n",
    "\n",
    "eig_val_cov, eig_vec_cov = np.linalg.eig(Cx)\n",
    "\n",
    "plt.plot(eig_val_cov)\n",
    "plt.title(\"Scree Plot for Flight Delay Data\")\n",
    "plt.show()\n",
    "\n",
    "# Calculate cumulative sum of variance explained with [n] features\n",
    "var=np.cumsum(np.round(sklearn_pca.explained_variance_ratio_, decimals=3)*100)\n",
    "plt.plot(var)\n",
    "plt.title(\"Cumulative Explained Variance\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A general rule of thumb is to keep only enough features to retain 85% of the variance. Judging by the plot above, we should keep 20 features. We will not transform our dataset to include 20 components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn_pca = PCA(n_components = 20)\n",
    "sklearn_pca.fit(X_scaled)\n",
    "X_train_pca = sklearn_pca.transform(X_scaled)\n",
    "X_train_pca_df = pd.DataFrame(data=X_pca)\n",
    "\n",
    "X_scaled_test = StandardScaler().fit_transform(X_test)\n",
    "sklearn_pca_test = PCA(n_components = 20)\n",
    "sklearn_pca_test.fit(X_scaled_test)\n",
    "X_test_pca = sklearn_pca.transform(X_scaled_test)\n",
    "X_test_pca_df = pd.DataFrame(data=X_test_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try re-running our logistic regressor with our PCA-transformed dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: 0.07649733101619145\n",
      "R2 Score: -11.059160582598297\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_linear_cv(X_train_pca_df, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: -10.854056662517486\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def run_linear_val(X_train, Y_train, X_test, Y_test):\n",
    "    lr = linear_model.LinearRegression()\n",
    "    lr.fit(X_train, Y_train)\n",
    "    Y_pred = lr.predict(X_test)\n",
    "\n",
    "    print(f'R2 Score: {r2_score(Y_pred, Y_test)}\\n') \n",
    "    \n",
    "run_linear_val(X_train_pca_df, Y_train, X_test_pca_df, Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is a poor fit for both our original and transformed datasets. The negative R2 score for training and validation supports this assertion. One possible reason for this is that linear regression assumes no multicollinearity between features, which is not the case here. Several of the features are closely linked to each other. We will use a more complicated algorithm that is better equipped to handle multicollinear features: decision tree/random forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 5, Max Feature = 5, Min Samples Split = 5\n",
      "Cross Validation Score: 0.046066575801417965\n",
      "R2 Score: -19.321753659932824\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Min Samples Split = 10\n",
      "Cross Validation Score: 0.046066575801417965\n",
      "R2 Score: -19.321753659932824\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Min Samples Split = 20\n",
      "Cross Validation Score: 0.046066575801417965\n",
      "R2 Score: -19.321753659932824\n",
      "\n",
      "Max Depth: 5, Max Feature = 10, Min Samples Split = 5\n",
      "Cross Validation Score: 0.07549094116703121\n",
      "R2 Score: -11.494024770559005\n",
      "\n",
      "Max Depth: 5, Max Feature = 10, Min Samples Split = 10\n",
      "Cross Validation Score: 0.07549094116703121\n",
      "R2 Score: -11.494024770559005\n",
      "\n",
      "Max Depth: 5, Max Feature = 10, Min Samples Split = 20\n",
      "Cross Validation Score: 0.07549094116703121\n",
      "R2 Score: -11.494024770559005\n",
      "\n",
      "Max Depth: 5, Max Feature = 20, Min Samples Split = 5\n",
      "Cross Validation Score: 0.07638906232327798\n",
      "R2 Score: -10.706088977284063\n",
      "\n",
      "Max Depth: 5, Max Feature = 20, Min Samples Split = 10\n",
      "Cross Validation Score: 0.07638906232327798\n",
      "R2 Score: -10.706088977284063\n",
      "\n",
      "Max Depth: 5, Max Feature = 20, Min Samples Split = 20\n",
      "Cross Validation Score: 0.07638906232327798\n",
      "R2 Score: -10.706088977284063\n",
      "\n",
      "Max Depth: 10, Max Feature = 5, Min Samples Split = 5\n",
      "Cross Validation Score: 0.09449321967513306\n",
      "R2 Score: -5.00432358208651\n",
      "\n",
      "Max Depth: 10, Max Feature = 5, Min Samples Split = 10\n",
      "Cross Validation Score: 0.09539368816548732\n",
      "R2 Score: -5.834616700006849\n",
      "\n",
      "Max Depth: 10, Max Feature = 5, Min Samples Split = 20\n",
      "Cross Validation Score: 0.1018112556157716\n",
      "R2 Score: -6.031299430577632\n",
      "\n",
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 5\n",
      "Cross Validation Score: 0.11931847483736102\n",
      "R2 Score: -4.92680777878671\n",
      "\n",
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 10\n",
      "Cross Validation Score: 0.11388652123891659\n",
      "R2 Score: -4.947641160585498\n",
      "\n",
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 20\n",
      "Cross Validation Score: 0.11415812108683299\n",
      "R2 Score: -4.972941361652821\n",
      "\n",
      "Max Depth: 10, Max Feature = 20, Min Samples Split = 5\n",
      "Cross Validation Score: 0.11490833201637314\n",
      "R2 Score: -4.576324276752687\n",
      "\n",
      "Max Depth: 10, Max Feature = 20, Min Samples Split = 10\n",
      "Cross Validation Score: 0.11515783602727003\n",
      "R2 Score: -4.599097672259802\n",
      "\n",
      "Max Depth: 10, Max Feature = 20, Min Samples Split = 20\n",
      "Cross Validation Score: 0.11644039208509005\n",
      "R2 Score: -4.631856754887079\n",
      "\n",
      "Max Depth: 20, Max Feature = 5, Min Samples Split = 5\n",
      "Cross Validation Score: -0.030490287041671598\n",
      "R2 Score: -0.7445579699948934\n",
      "\n",
      "Max Depth: 20, Max Feature = 5, Min Samples Split = 10\n",
      "Cross Validation Score: 0.007646247988841133\n",
      "R2 Score: -0.5778967293504753\n",
      "\n",
      "Max Depth: 20, Max Feature = 5, Min Samples Split = 20\n",
      "Cross Validation Score: 0.044449957220202986\n",
      "R2 Score: -0.8699945069512058\n",
      "\n",
      "Max Depth: 20, Max Feature = 10, Min Samples Split = 5\n",
      "Cross Validation Score: -0.03958855870417577\n",
      "R2 Score: -0.3275497248878094\n",
      "\n",
      "Max Depth: 20, Max Feature = 10, Min Samples Split = 10\n",
      "Cross Validation Score: -0.00660409037208017\n",
      "R2 Score: -0.5480451665998312\n",
      "\n",
      "Max Depth: 20, Max Feature = 10, Min Samples Split = 20\n",
      "Cross Validation Score: 0.03733121569823986\n",
      "R2 Score: -0.7136189753131224\n",
      "\n",
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 5\n",
      "Cross Validation Score: -0.053998198113338614\n",
      "R2 Score: -0.06933443110593096\n",
      "\n",
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 10\n",
      "Cross Validation Score: -0.021563758833046103\n",
      "R2 Score: -0.20717770709942407\n",
      "\n",
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 20\n",
      "Cross Validation Score: 0.016724008697572474\n",
      "R2 Score: -0.40501290275704416\n",
      "\n",
      "{'max depth': 10, 'max features': 10, 'min samples split': 5, 'cross-val score': 0.11931847483736102, 'r2 score': -4.9268077787867099}\n"
     ]
    }
   ],
   "source": [
    "def run_tree_cv (X, Y, depth_max, feature_max, min_split):\n",
    "\n",
    "    dtree = DecisionTreeRegressor(\n",
    "        max_depth = depth_max,\n",
    "        random_state = 1,\n",
    "        max_features = feature_max,\n",
    "        min_samples_split = min_split\n",
    "    )\n",
    "    dtree.fit(X, Y)\n",
    "    \n",
    "    scores = cross_validation.cross_val_score(dtree, X, Y, cv=3)\n",
    "    Y_pred = dtree.predict(X)\n",
    "    \n",
    "    print(f'Max Depth: {depth_max}, Max Feature = {feature_max}, Min Samples Split = {min_split}')\n",
    "    print(f'Cross Validation Score: {scores.mean()}')\n",
    "    print(f'R2 Score: {r2_score(Y_pred, Y)}\\n')\n",
    "    \n",
    "    current_run = {'max depth': depth_max, \n",
    "                    'max features': feature_max,\n",
    "                    'min samples split': min_split,\n",
    "                    'cross-val score': scores.mean(),\n",
    "                    'r2 score': r2_score(Y_pred, Y)}\n",
    "    runs.append(current_run)\n",
    "\n",
    "runs = []\n",
    "depth_maxs = [5, 10, 20]\n",
    "feature_maxs = [5, 10, 20]\n",
    "min_splits = [5, 10, 20]\n",
    "\n",
    "for depth_max in depth_maxs:\n",
    "        for feature_max in feature_maxs:\n",
    "            for min_split in min_splits:\n",
    "                run_tree_cv(X_train_pca_df, Y_train, depth_max, feature_max, min_split)\n",
    "                    \n",
    "runs.sort(key = lambda run: run['cross-val score'])\n",
    "print(runs[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 5\n",
      "R2 Score: -5.047414756861527\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree_maxdp = runs[-1]['max depth']\n",
    "tree_maxft = runs[-1]['max features']\n",
    "tree_minss = runs[-1]['min samples split']\n",
    "\n",
    "def run_tree_val(X_train, Y_train, X_test, Y_test, depth_max, feature_max, min_split):\n",
    "    dtree = DecisionTreeRegressor(\n",
    "        max_depth = depth_max,\n",
    "        random_state = 1,\n",
    "        max_features = feature_max,\n",
    "        min_samples_split = min_split\n",
    "    )\n",
    "    dtree.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = dtree.predict(X_test)\n",
    "    \n",
    "    print(f'Max Depth: {depth_max}, Max Feature = {feature_max}, Min Samples Split = {min_split}')\n",
    "    print(f'R2 Score: {r2_score(Y_pred, Y_test)}\\n')\n",
    "    \n",
    "run_tree_val(X_train_pca_df, Y_train, X_test_pca_df, Y_test, tree_maxdp, tree_maxft, tree_minss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running 2 different machine learning models, we still have a negative R2 score. It is possible that this dataset is not able to be fit with a regression equation. While it would be useful to predict a continuous value for how late a flight will be, the features we have may necessitate that we turn this into a classification problem and simply predict \"late\" or \"not late\".<br>\n",
    "\n",
    "So, we will add a binary feature that specifies 1 if late or 0 if on time and alter our models to predict a binary output. Now that we are predicting a binary output, we will change our success metric from R2 score to accuracy. We will start with logistic regression since it is inexpensive to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: late, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "combined['late'] = np.where(combined['LateAircraftDelay']>30, 1, 0)\n",
    "X_b = combined.drop(['LateAircraftDelay','late'],axis=1)\n",
    "Y_b = combined['late']\n",
    "X_train_b, X_test_b, Y_train_b, Y_test_b = train_test_split(X_b, Y_b, test_size = 0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_logistic_cv(X, Y, a, pen):\n",
    "    lr = LogisticRegression(C = a, penalty = pen, random_state = 1)\n",
    "    lr.fit(X, Y)\n",
    "\n",
    "    scores = cross_validation.cross_val_score(lr, X, Y, cv=5, scoring = 'accuracy')\n",
    "    Y_pred = lr.predict(X)\n",
    "    \n",
    "    print(f'Penalty: {pen}\\t Lambda: {a}')\n",
    "    print(f'Cross Validation Score: {scores.mean()}')\n",
    "    print(f'Accuracy: {accuracy_score(Y_pred, Y)}\\n')\n",
    "    \n",
    "    current_run = {'penalty': pen, 'lambda': a, 'cross-val score': scores.mean(), 'accuracy': accuracy_score(Y_pred, Y)}\n",
    "    runs.append(current_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.01\n",
      "Cross Validation Score: 0.6686810258237526\n",
      "Accuracy: 0.6688645938408592\n",
      "\n",
      "Lambda: 0.1\n",
      "Cross Validation Score: 0.668938769265979\n",
      "Accuracy: 0.6690555835756246\n",
      "\n",
      "Lambda: 0.5\n",
      "Cross Validation Score: 0.6689851258945698\n",
      "Accuracy: 0.6691037945766333\n",
      "\n",
      "Lambda: 1\n",
      "Cross Validation Score: 0.6689943973612582\n",
      "Accuracy: 0.6691241915385985\n",
      "\n",
      "Lambda: 100\n",
      "Cross Validation Score: 0.6689851260664847\n",
      "Accuracy: 0.6691167744615202\n",
      "\n",
      "Lambda: 0.01\n",
      "Cross Validation Score: 0.6687440711989696\n",
      "Accuracy: 0.6687088352222156\n",
      "\n",
      "Lambda: 0.1\n",
      "Cross Validation Score: 0.6690314842938829\n",
      "Accuracy: 0.6692317391562334\n",
      "\n",
      "Lambda: 0.5\n",
      "Cross Validation Score: 0.6690333375007192\n",
      "Accuracy: 0.6689962469589984\n",
      "\n",
      "Lambda: 1\n",
      "Cross Validation Score: 0.669022211469068\n",
      "Accuracy: 0.6692484275796594\n",
      "\n",
      "Lambda: 100\n",
      "Cross Validation Score: 0.6690314826091182\n",
      "Accuracy: 0.6692984928499377\n",
      "\n",
      "{'lambda': 0.5, 'cross-val score': 0.66903333750071925, 'accuracy': 0.6689962469589984}\n"
     ]
    }
   ],
   "source": [
    "runs = []\n",
    "alphas = [0.01, 0.1, 0.5, 1, 100]\n",
    "penalties = ['l1','l2']\n",
    "\n",
    "for pen in penalties:\n",
    "    for a in alphas:\n",
    "        run_logistic_cv(X_train_b, Y_train_b, a, pen)\n",
    "\n",
    "runs.sort(key = lambda run: run['cross-val score'])\n",
    "print(runs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Despite changing our lambda value, the accuracy remained at roughly 67% for every iteration. While this is certainly better than our negative R2 value, it is not particularly impressive. Our best model came from a ridge regression and a lambda = 0.5 with moderate regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lambda: 0.5\n",
      "Accuracy: 0.669977155402599\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_lambda = runs[-1]['lambda']\n",
    "lr_pen = 'l2'\n",
    "\n",
    "def run_logistic_val(X_train, Y_train, X_test, Y_test, lr_lambda, lr_pen):\n",
    "    lr = LogisticRegression(C = lr_lambda, penalty = lr_pen, random_state = 1)\n",
    "    lr.fit(X_train, Y_train)\n",
    "    Y_pred = lr.predict(X_test)\n",
    "\n",
    "    print(f'Lambda: {lr_lambda}')\n",
    "    print(f'Accuracy: {accuracy_score(Y_pred, Y_test)}\\n') \n",
    "    \n",
    "run_logistic_val(X_train_b, Y_train_b, X_test_b, Y_test_b, lr_lambda, lr_pen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After validating with an unseen portion of the original dataset, our accuracy remains unchanged. This means that the model is underfitting. Logistic regression operates on the principle that the features are not multicollinear, which may explain why this model is fitting so poorly. <br>\n",
    "\n",
    "Let's try random forest, a more complex algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 5, Max Feature = 5, Min Samples Split = 5, n = 10\n",
      "Cross Validation Score: 0.6598806637521706\n",
      "Accuracy Score: 0.6606501809766807\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Min Samples Split = 5, n = 50\n",
      "Cross Validation Score: 0.6696934526628823\n",
      "Accuracy Score: 0.6710748828101821\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Min Samples Split = 10, n = 10\n",
      "Cross Validation Score: 0.6598806637521706\n",
      "Accuracy Score: 0.6606501809766807\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Min Samples Split = 10, n = 50\n",
      "Cross Validation Score: 0.6688998304423205\n",
      "Accuracy Score: 0.6704221800272948\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Min Samples Split = 20, n = 10\n",
      "Cross Validation Score: 0.6590221344259491\n",
      "Accuracy Score: 0.6632313237999169\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Min Samples Split = 20, n = 50\n",
      "Cross Validation Score: 0.668521559284389\n",
      "Accuracy Score: 0.6711249480804604\n",
      "\n",
      "Max Depth: 5, Max Feature = 10, Min Samples Split = 5, n = 10\n",
      "Cross Validation Score: 0.6747834262846837\n",
      "Accuracy Score: 0.6773645641725509\n",
      "\n",
      "Max Depth: 5, Max Feature = 10, Min Samples Split = 5, n = 50\n",
      "Cross Validation Score: 0.6773126443765675\n",
      "Accuracy Score: 0.6793949890227259\n",
      "\n",
      "Max Depth: 5, Max Feature = 10, Min Samples Split = 10, n = 10\n",
      "Cross Validation Score: 0.6766321324920558\n",
      "Accuracy Score: 0.6773645641725509\n",
      "\n",
      "Max Depth: 5, Max Feature = 10, Min Samples Split = 10, n = 50\n",
      "Cross Validation Score: 0.6764281575842506\n",
      "Accuracy Score: 0.6780803121106035\n",
      "\n",
      "Max Depth: 5, Max Feature = 10, Min Samples Split = 20, n = 10\n",
      "Cross Validation Score: 0.6780524974850652\n",
      "Accuracy Score: 0.6773645641725509\n",
      "\n",
      "Max Depth: 5, Max Feature = 10, Min Samples Split = 20, n = 50\n",
      "Cross Validation Score: 0.6759293628572404\n",
      "Accuracy Score: 0.6777966089123598\n",
      "\n",
      "Max Depth: 5, Max Feature = 20, Min Samples Split = 5, n = 10\n",
      "Cross Validation Score: 0.6822413016675132\n",
      "Accuracy Score: 0.687025307066991\n",
      "\n",
      "Max Depth: 5, Max Feature = 20, Min Samples Split = 5, n = 50\n",
      "Cross Validation Score: 0.6866563060983975\n",
      "Accuracy Score: 0.6842958227021895\n",
      "\n",
      "Max Depth: 5, Max Feature = 20, Min Samples Split = 10, n = 10\n",
      "Cross Validation Score: 0.6834781084025452\n",
      "Accuracy Score: 0.687025307066991\n",
      "\n",
      "Max Depth: 5, Max Feature = 20, Min Samples Split = 10, n = 50\n",
      "Cross Validation Score: 0.687284902658749\n",
      "Accuracy Score: 0.6842958227021895\n",
      "\n",
      "Max Depth: 5, Max Feature = 20, Min Samples Split = 20, n = 10\n",
      "Cross Validation Score: 0.6834243347931492\n",
      "Accuracy Score: 0.6837710644989022\n",
      "\n",
      "Max Depth: 5, Max Feature = 20, Min Samples Split = 20, n = 50\n",
      "Cross Validation Score: 0.6870457033464358\n",
      "Accuracy Score: 0.6845684002848158\n",
      "\n",
      "Max Depth: 10, Max Feature = 5, Min Samples Split = 5, n = 10\n",
      "Cross Validation Score: 0.715193516326166\n",
      "Accuracy Score: 0.7240272503411855\n",
      "\n",
      "Max Depth: 10, Max Feature = 5, Min Samples Split = 5, n = 50\n",
      "Cross Validation Score: 0.7286981580827175\n",
      "Accuracy Score: 0.7343481130955913\n",
      "\n",
      "Max Depth: 10, Max Feature = 5, Min Samples Split = 10, n = 10\n",
      "Cross Validation Score: 0.7142645079680321\n",
      "Accuracy Score: 0.7253159674835341\n",
      "\n",
      "Max Depth: 10, Max Feature = 5, Min Samples Split = 10, n = 50\n",
      "Cross Validation Score: 0.7222656985709309\n",
      "Accuracy Score: 0.7324994066338337\n",
      "\n",
      "Max Depth: 10, Max Feature = 5, Min Samples Split = 20, n = 10\n",
      "Cross Validation Score: 0.7163450261865533\n",
      "Accuracy Score: 0.729792173500267\n",
      "\n",
      "Max Depth: 10, Max Feature = 5, Min Samples Split = 20, n = 50\n",
      "Cross Validation Score: 0.7232744098652858\n",
      "Accuracy Score: 0.7334172699222691\n",
      "\n",
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 5, n = 10\n",
      "Cross Validation Score: 0.753039143983972\n",
      "Accuracy Score: 0.7670425888565834\n",
      "\n",
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 5, n = 50\n",
      "Cross Validation Score: 0.7677861503528028\n",
      "Accuracy Score: 0.7740721236575091\n",
      "\n",
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 10, n = 10\n",
      "Cross Validation Score: 0.7665437829554783\n",
      "Accuracy Score: 0.7604080134100754\n",
      "\n",
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 10, n = 50\n",
      "Cross Validation Score: 0.7711701841298911\n",
      "Accuracy Score: 0.7733044561799086\n",
      "\n",
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 20, n = 10\n",
      "Cross Validation Score: 0.7524198146714823\n",
      "Accuracy Score: 0.7665474989616092\n",
      "\n",
      "Max Depth: 10, Max Feature = 10, Min Samples Split = 20, n = 50\n",
      "Cross Validation Score: 0.7685018904996256\n",
      "Accuracy Score: 0.7734472349136652\n",
      "\n",
      "Max Depth: 10, Max Feature = 20, Min Samples Split = 5, n = 10\n",
      "Cross Validation Score: 0.7855018355370288\n",
      "Accuracy Score: 0.7977066397674004\n",
      "\n",
      "Max Depth: 10, Max Feature = 20, Min Samples Split = 5, n = 50\n",
      "Cross Validation Score: 0.79323413428597\n",
      "Accuracy Score: 0.7976936598825135\n",
      "\n",
      "Max Depth: 10, Max Feature = 20, Min Samples Split = 10, n = 10\n",
      "Cross Validation Score: 0.7859190375818877\n",
      "Accuracy Score: 0.7914188126743014\n",
      "\n",
      "Max Depth: 10, Max Feature = 20, Min Samples Split = 10, n = 50\n",
      "Cross Validation Score: 0.792891099642335\n",
      "Accuracy Score: 0.8003063252833323\n",
      "\n",
      "Max Depth: 10, Max Feature = 20, Min Samples Split = 20, n = 10\n",
      "Cross Validation Score: 0.7867701663831381\n",
      "Accuracy Score: 0.7999113659289148\n",
      "\n",
      "Max Depth: 10, Max Feature = 20, Min Samples Split = 20, n = 50\n",
      "Cross Validation Score: 0.7895997745700827\n",
      "Accuracy Score: 0.7977066397674004\n",
      "\n",
      "Max Depth: 20, Max Feature = 5, Min Samples Split = 5, n = 10\n",
      "Cross Validation Score: 0.798859979341836\n",
      "Accuracy Score: 0.8718050940485373\n",
      "\n",
      "Max Depth: 20, Max Feature = 5, Min Samples Split = 5, n = 50\n",
      "Cross Validation Score: 0.8158191384459803\n",
      "Accuracy Score: 0.8923114579006705\n",
      "\n",
      "Max Depth: 20, Max Feature = 5, Min Samples Split = 10, n = 10\n",
      "Cross Validation Score: 0.8011277567100339\n",
      "Accuracy Score: 0.8662756630866908\n",
      "\n",
      "Max Depth: 20, Max Feature = 5, Min Samples Split = 10, n = 50\n",
      "Cross Validation Score: 0.8178402878169937\n",
      "Accuracy Score: 0.8864593840859194\n",
      "\n",
      "Max Depth: 20, Max Feature = 5, Min Samples Split = 20, n = 10\n",
      "Cross Validation Score: 0.7933917436392871\n",
      "Accuracy Score: 0.8482818340948199\n",
      "\n",
      "Max Depth: 20, Max Feature = 5, Min Samples Split = 20, n = 50\n",
      "Cross Validation Score: 0.8159952961789868\n",
      "Accuracy Score: 0.8683450275915268\n",
      "\n",
      "Max Depth: 20, Max Feature = 10, Min Samples Split = 5, n = 10\n",
      "Cross Validation Score: 0.8351091058938277\n",
      "Accuracy Score: 0.9091704740995669\n",
      "\n",
      "Max Depth: 20, Max Feature = 10, Min Samples Split = 5, n = 50\n",
      "Cross Validation Score: 0.847727404532673\n",
      "Accuracy Score: 0.918719960837833\n",
      "\n",
      "Max Depth: 20, Max Feature = 10, Min Samples Split = 10, n = 10\n",
      "Cross Validation Score: 0.8366166286048334\n",
      "Accuracy Score: 0.8949723343024981\n",
      "\n",
      "Max Depth: 20, Max Feature = 10, Min Samples Split = 10, n = 50\n",
      "Cross Validation Score: 0.8474807858396023\n",
      "Accuracy Score: 0.9072865365216876\n",
      "\n",
      "Max Depth: 20, Max Feature = 10, Min Samples Split = 20, n = 10\n",
      "Cross Validation Score: 0.8360881647511874\n",
      "Accuracy Score: 0.8864853438556933\n",
      "\n",
      "Max Depth: 20, Max Feature = 10, Min Samples Split = 20, n = 50\n",
      "Cross Validation Score: 0.8469634440532202\n",
      "Accuracy Score: 0.8950075654186198\n",
      "\n",
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 5, n = 10\n",
      "Cross Validation Score: 0.8440188669149103\n",
      "Accuracy Score: 0.9109728238295852\n",
      "\n",
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 5, n = 50\n",
      "Cross Validation Score: 0.8518309052595178\n",
      "Accuracy Score: 0.9175721681599716\n",
      "\n",
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 10, n = 10\n",
      "Cross Validation Score: 0.8448440170012029\n",
      "Accuracy Score: 0.901128508277458\n",
      "\n",
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 10, n = 50\n",
      "Cross Validation Score: 0.8520218939146537\n",
      "Accuracy Score: 0.9083712840443838\n",
      "\n",
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 20, n = 10\n",
      "Cross Validation Score: 0.845151825548673\n",
      "Accuracy Score: 0.8883766985106509\n",
      "\n",
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 20, n = 50\n",
      "Cross Validation Score: 0.8515323682096821\n",
      "Accuracy Score: 0.89611827271109\n",
      "\n",
      "{'max depth': 20, 'max features': 20, 'min samples split': 10, 'n': 50, 'cross-val score': 0.85202189391465366, 'r2 score': 0.62615613484736332}\n"
     ]
    }
   ],
   "source": [
    "def run_forest_cv (X, Y, depth_max, feature_max, min_split,n):\n",
    "\n",
    "    rfr = RandomForestClassifier(\n",
    "        max_depth = depth_max,\n",
    "        random_state = 1,\n",
    "        max_features = feature_max,\n",
    "        min_samples_split = min_split,\n",
    "        n_estimators = n\n",
    "    )\n",
    "    rfr.fit(X, Y)\n",
    "    \n",
    "    scores = cross_validation.cross_val_score(rfr, X, Y, cv=3, scoring = 'accuracy')\n",
    "    Y_pred = rfr.predict(X)\n",
    "    \n",
    "    print(f'Max Depth: {depth_max}, Max Feature = {feature_max}, Min Samples Split = {min_split}, n = {n}')\n",
    "    print(f'Cross Validation Score: {scores.mean()}')\n",
    "    print(f'Accuracy Score: {accuracy_score(Y_pred, Y)}\\n')\n",
    "    \n",
    "    current_run = {'max depth': depth_max, \n",
    "                    'max features': feature_max,\n",
    "                    'min samples split': min_split,\n",
    "                    'n':n,\n",
    "                    'cross-val score': scores.mean(),\n",
    "                    'accuracy': accuracy_score(Y_pred, Y)}\n",
    "    runs.append(current_run)\n",
    "\n",
    "runs = []\n",
    "depth_maxs = [5, 10, 20]\n",
    "feature_maxs = [5, 10, 20]\n",
    "min_splits = [5, 10, 20]\n",
    "ns = [10, 50]\n",
    "\n",
    "for depth_max in depth_maxs:\n",
    "    for feature_max in feature_maxs:\n",
    "        for min_split in min_splits:\n",
    "            for n in ns:\n",
    "                run_forest_cv(X_train_b, Y_train_b, depth_max, feature_max, min_split,n)\n",
    "                    \n",
    "runs.sort(key = lambda run: run['cross-val score'])\n",
    "print(runs[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a cross-validation average of **85% accuracy**, the random forest is so far our best model. This was achieved using max depth = 20, max features = 20, min samples split = 10, and 50 estimators. Both max depth and max features used the highest available value, which indicates that the model might perform even better if the maximum is raised even higher. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 20, Max Feature = 20, Min Samples Split = 10, n = 50\n",
      "Accuracy: 0.8540319230997448\n",
      "\n"
     ]
    }
   ],
   "source": [
    "forest_maxdp = runs[-1]['max depth']\n",
    "forest_maxft = runs[-1]['max features']\n",
    "forest_minss = runs[-1]['min samples split']\n",
    "forest_n = runs[-1]['n']\n",
    "\n",
    "def run_forest_val(X_train, Y_train, X_test, Y_test, depth_max, feature_max, min_split, n):\n",
    "    rfr = RandomForestClassifier(\n",
    "        max_depth = depth_max,\n",
    "        random_state = 1,\n",
    "        max_features = feature_max,\n",
    "        min_samples_split = min_split,\n",
    "        n_estimators = n\n",
    "    )\n",
    "    rfr.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = rfr.predict(X_test)\n",
    "    \n",
    "    print(f'Max Depth: {depth_max}, Max Feature = {feature_max}, Min Samples Split = {min_split}, n = {n}')\n",
    "    print(f'Accuracy: {accuracy_score(Y_pred, Y_test)}\\n')\n",
    "    \n",
    "run_forest_val(X_train_b, Y_train_b, X_test_b, Y_test_b, forest_maxdp, forest_maxft, forest_minss, forest_n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a validation accuracy of **0.854**, we can see that the model is not overfitting since it is generalizing well to unseen data. Since this ensemble model worked well, let's try another ensemble model with higher interpretability: gradient boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max depth': 5, 'subsample': 0.1, 'learning rate': 0.1, 'cross-val score': 0.82881385344398517, 'accuracy': 0.83119659704503646, 'feature list': ['Year', 'UniqueCarrier_AQ', 'UniqueCarrier_AS', 'UniqueCarrier_HA', 'UniqueCarrier_US', 'UniqueCarrier_AA', 'UniqueCarrier_9E', 'UniqueCarrier_XE', 'UniqueCarrier_DL', 'UniqueCarrier_B6', 'UniqueCarrier_OO', 'UniqueCarrier_MQ', 'DayOfWeek', 'UniqueCarrier_CO', 'UniqueCarrier_FL', 'UniqueCarrier_WN', 'UniqueCarrier_UA', 'UniqueCarrier_F9', 'Distance', 'UniqueCarrier_NW', 'CRSElapsedTime', 'DayofMonth', 'AirTime', 'TaxiIn', 'UniqueCarrier_YV', 'UniqueCarrier_EV', 'UniqueCarrier_OH', 'ActualElapsedTime', 'TaxiOut', 'Month', 'CRSArrTime', 'ArrTime', 'CRSDepTime', 'DepTime']}\n",
      "Max Depth: 5, Subsample = 0.1, Learning Rate = 0.1\n",
      "Accuracy: 0.8285839316442176\n",
      "\n",
      "Feature List: ['Year', 'UniqueCarrier_AQ', 'UniqueCarrier_AS', 'UniqueCarrier_HA', 'UniqueCarrier_US', 'UniqueCarrier_AA', 'UniqueCarrier_9E', 'UniqueCarrier_XE', 'UniqueCarrier_DL', 'UniqueCarrier_B6', 'UniqueCarrier_OO', 'UniqueCarrier_MQ', 'DayOfWeek', 'UniqueCarrier_CO', 'UniqueCarrier_FL', 'UniqueCarrier_WN', 'UniqueCarrier_UA', 'UniqueCarrier_F9', 'Distance', 'UniqueCarrier_NW', 'CRSElapsedTime', 'DayofMonth', 'AirTime', 'TaxiIn', 'UniqueCarrier_YV', 'UniqueCarrier_EV', 'UniqueCarrier_OH', 'ActualElapsedTime', 'TaxiOut', 'Month', 'CRSArrTime', 'ArrTime', 'CRSDepTime', 'DepTime']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "def run_boosting(X_train, Y_train, X_test, Y_test):\n",
    "\n",
    "    # Function to find best parameters using cross-validation\n",
    "    def boosting(depth_max, subsample, learn):\n",
    "        gbc = ensemble.GradientBoostingClassifier(max_depth=depth_max,\n",
    "                                                  random_state=1,\n",
    "                                                  subsample=ss,\n",
    "                                                  learning_rate = learn\n",
    "        )\n",
    "        gbc.fit(X_train, Y_train)\n",
    "        \n",
    "        scores = cross_validation.cross_val_score(gbc, X_train, Y_train, cv=3, scoring = 'accuracy')\n",
    "        Y_pred = gbc.predict(X_train)\n",
    "    \n",
    "        feature_importance = gbc.feature_importances_\n",
    "        feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "        sorted_idx = np.argsort(feature_importance)\n",
    "        sorted_col = X_train.columns[sorted_idx].tolist()\n",
    "        \n",
    "        current_run = {'max depth': depth_max, \n",
    "                    'subsample': ss,\n",
    "                    'learning rate': learn,\n",
    "                    'cross-val score': scores.mean(),\n",
    "                    'accuracy': accuracy_score(Y_pred, Y_train),\n",
    "                    'feature list': sorted_col}\n",
    "                    \n",
    "        runs.append(current_run)\n",
    "        return current_run\n",
    "        \n",
    "    # Define parameters to iterate through and where to store iterations\n",
    "    depth_maxs = [5, 10, 20]\n",
    "    subsamples = [0.1, 0.5, 1]\n",
    "    learning_rates = [0.1, 0.5, 1]\n",
    "    \n",
    "    runs = []\n",
    "    \n",
    "    for depth_max in depth_maxs:\n",
    "        for ss in subsamples:\n",
    "            for learn in learning_rates:\n",
    "                runs.append(boosting(depth_max, ss, learn))\n",
    "    \n",
    "    # Extract best parameters\n",
    "    runs.sort(key = lambda run: run['cross-val score'])\n",
    "    \n",
    "    features = runs[-1]['feature list']\n",
    "    depth_max = runs[-1]['max depth']\n",
    "    ss = runs[-1]['subsample']\n",
    "    learn = runs[-1]['learning rate']\n",
    "    \n",
    "    # Validation with test dataset\n",
    "    gbc = ensemble.GradientBoostingClassifier(max_depth = depth_max,\n",
    "                                              random_state = 1,\n",
    "                                              subsample = ss,\n",
    "                                              learning_rate = learn\n",
    "    )\n",
    "    gbc.fit(X_train, Y_train)\n",
    "    \n",
    "    Y_pred = gbc.predict(X_test)\n",
    "    \n",
    "    print(f'Max Depth: {depth_max}, Subsample = {ss}, Learning Rate = {learn}')\n",
    "    print(f'Accuracy: {accuracy_score(Y_pred, Y_test)}\\n')\n",
    "    print(f'Feature List: {features}')\n",
    "    return features\n",
    "\n",
    "best_features = run_boosting(X_train_b, Y_train_b, X_test_b, Y_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(best_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
